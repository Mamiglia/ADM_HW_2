{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"07c06436-c72f-4c4d-ba3e-9cdbd9a54095","_uuid":"706fc22f-3e4f-4926-b39d-710b689977a5"},"source":["# __Homework 2 - Instagram Profiles & Posts__\n","\n","Libraries:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0306b8e-4aee-41e3-9968-bacc2831f258","_uuid":"c88e97d6-5f42-42f0-a136-719ef42d6b30","execution":{"iopub.status.busy":"2022-10-27T18:49:19.638862Z","iopub.status.idle":"2022-10-27T18:49:19.639212Z","shell.execute_reply":"2022-10-27T18:49:19.639055Z","shell.execute_reply.started":"2022-10-27T18:49:19.639038Z"},"tags":[],"trusted":true},"outputs":[],"source":["%pip install pyarrow"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c32f0e34-3c45-4b0d-b175-891396479cdd","_uuid":"1bacf12e-3b11-4121-adde-a2c27c4d5c06","execution":{"iopub.execute_input":"2022-10-27T20:37:43.969875Z","iopub.status.busy":"2022-10-27T20:37:43.969359Z","iopub.status.idle":"2022-10-27T20:37:44.780726Z","shell.execute_reply":"2022-10-27T20:37:44.779284Z","shell.execute_reply.started":"2022-10-27T20:37:43.969833Z"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import random\n","import re\n","import os\n","import datatable as dt\n","from math import pi, floor, log10, ceil\n","\n","\n","SAMPLE_SIZE = 10000\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","sns.set(rc={'figure.figsize':(10,5)})\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6b4fa853-56d6-485d-82e0-9ed0940dfdee","_uuid":"618808ec-4ab8-4684-b28a-3f289227188c"},"source":["***\n","\n","## __Preprocessing__\n","\n","We create a `Dataset` class that will help us manage the 3 datasets throughout the processing. As the datasets are very big, we settled to load only some columns for each question. This is managed by the \n","```python\n","Dataset.col(columns:list) -> pd.DataFrame\n","``` \n","method that will be used multiple times throughout the homework to selectively load only some columns from the csv files, using `datatable` library as it is more efficient in the usage of multiple cores, and loads way faster. Then the `datatable` object is casted to a common `pandas` DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fbc54ff-e608-4d4a-8d8d-fe23ce104af6","_uuid":"65c87509-9868-4312-8198-f77d4f600cc9","execution":{"iopub.execute_input":"2022-10-27T20:37:44.785069Z","iopub.status.busy":"2022-10-27T20:37:44.783294Z","iopub.status.idle":"2022-10-27T20:37:44.805259Z","shell.execute_reply":"2022-10-27T20:37:44.803282Z","shell.execute_reply.started":"2022-10-27T20:37:44.785006Z"},"trusted":true},"outputs":[],"source":["class Dataset:\n","    def __init__(self, file:str):\n","        self.file_name : str = file\n","        self.types : dict = self.load_types()\n","        self.df : pd.DataFrame = None\n","        \n","    def name(self):\n","        return re.search(r'\\/([\\w\\d]*)\\.csv',self.file_name).group(1)\n","    \n","    def __types_file__(self):\n","        return 'types/' + self.name() +'.npy'\n","        \n","    def save_types(self):\n","        with open(self.__types_file__(), 'wb') as f:\n","            np.save(f, self.types)\n","        \n","    def load_types(self):\n","        if os.path.isfile(self.__types_file__()):\n","            self.types = np.load(self.__types_file__(),allow_pickle='TRUE').item()\n","            return self.types\n","        return None\n","    \n","    def col(self,columns:list, index=True,pandas=False,**dt_params)->pd.DataFrame:\n","        \"\"\"Loads some columns of the dataframe out of the whole csv file\n","        \n","        :param columns: a list of the desired columns\n","        :type columns: list\n","        :param index: if True loads also the 'sid' column as the index\n","        :type index: bool\n","        :param **pd_params: any other params for pd.read_csv(...)\n","        :rtype: pd.DataFrame\n","        \"\"\"\n","        col_list = columns\n","        if index==True:\n","            col_list.append('sid')\n","        if pandas:\n","            return pd.read_csv(self.file_name,\n","                           usecols=col_list,\n","                           dtype=self.types, \n","                           index_col='sid' if index==True else index,\n","                           delimiter='\\t',\n","                           **dt_params)\n","        d = dt.fread(self.file_name,\n","                           columns=set(col_list),\n","                           sep='\\t',\n","                            **dt_params)\n","        if index == True:\n","            d.key = 'sid'\n","        elif index:\n","            d.key = index\n","        d = d.to_pandas().astype({k:v for k,v in self.types.items() if k in d.names})\n","        if 'cts' in col_list:\n","            d['cts'] = pd.to_datetime(d['cts'])\n","#             d = d.astype({'cts': 'datetime64'})\n","        return d\n","\n","datasets = [\n","    Dataset(file='../input/instagram-dataset/instagram_profiles.csv'), \n","    Dataset(file='../input/instagram-dataset/instagram_locations.csv'), \n","    Dataset(file='../input/instagram-dataset/instagram_posts.csv')\n","]\n","profiles, locations, posts = datasets"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f6135a1f-17c8-48a6-b347-ec48c26e7c3d","_uuid":"448d6056-01f4-48ed-9551-6e8fcb60ad59"},"source":["We inferred most of the types of the columns from the descriptions [here](https://www.kaggle.com/datasets/shmalex/instagram-dataset/versions/3), at least for what regard whether they are numeric, `boolean`, string type or something else.\n","We want to optimize the `dtype` of each column since in this way we'll save some precious memory space, and overall ease the computation.\n","\n","For **numeric** and **string** dtypes:\n","- if they can assume only a small number of values we cast the to `categorical`, which is a special `dtype` that represents categorical data. This was applied to columns: \n","    - 'post_type': [1,2,3]\n","    - 'cd' : country names (around 200 values)\n","    \n","For **numeric** dtypes:\n","- if they're integer we temporarily assign them to `Int64`, but further optimization will be performed later\n","- else they're assigned as `float`\n","    - 'lat' and 'lng' are assigned directly as `Float32` since the values they contain are in a fairly small range with not much precision needed\n","\n","For **string** dtypes:\n","- if they represent dates they will be casted to `datetime64[ns,]` in the `Datetime.col()` method\n","    - 'cts'\n","- they are assigned as `pd.StringDtype(storage='pyarrow')` as we noted that this (experimental) dtype allows us to highly improve memory usage\n","    - this is appllied to the majority of columns"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b53598f0-c440-4b32-965f-97d1161a6f5b","_uuid":"be8f9ded-3c4d-4d92-b523-0fc21c8bb3b3","execution":{"iopub.execute_input":"2022-10-27T20:37:44.807755Z","iopub.status.busy":"2022-10-27T20:37:44.807302Z","iopub.status.idle":"2022-10-27T20:37:44.835305Z","shell.execute_reply":"2022-10-27T20:37:44.833540Z","shell.execute_reply.started":"2022-10-27T20:37:44.807715Z"},"trusted":true},"outputs":[],"source":["profiles.types = {\n","#     'sid' : 'Int64',\n","    'profile_id' : 'Int64',\n","    'profile_name' : pd.StringDtype(storage='pyarrow'),\n","    'firstname_lastname' : pd.StringDtype(storage='pyarrow'),\n","    'description' : pd.StringDtype(storage='pyarrow'),\n","    'following' : 'Int64',\n","    'followers' : 'Int64',\n","    'n_posts' : 'Int64',\n","    'url' : pd.StringDtype(storage='pyarrow'),\n","#     'cts' : pd.DatetimeTZDtype(tz='UTC'), #obtained through parse_dates=['cts']\n","    'is_business_account' : pd.BooleanDtype()\n","}\n","posts.types = {\n","#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n","    'sid_profile' : 'Int64',\n","    'post_id' : pd.StringDtype(storage='pyarrow'),\n","    'profile_id' : 'Int64',\n","    'location_id' : 'Int64',\n","    'description' : pd.StringDtype(storage='pyarrow'),\n","    'post_type' : pd.CategoricalDtype(categories=[1,2,3]),\n","    'numbr_likes' : 'Int64',\n","    'number_comments' : 'Int64'\n","}\n","locations.types = {\n","#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n","    'id' : 'Int64',\n","    'name' : pd.StringDtype(storage='pyarrow'),\n","    'street' : pd.StringDtype(storage='pyarrow'),\n","    'zip' : pd.StringDtype(storage='pyarrow'),\n","    'city' : pd.StringDtype(storage='pyarrow'),\n","    'region' : pd.StringDtype(storage='pyarrow'),\n","    'cd' : pd.CategoricalDtype(),\n","    'phone' : pd.StringDtype(storage='pyarrow'),\n","    'aj_exact_city_match' : pd.BooleanDtype(),\n","    'aj_exact_country_match' : pd.BooleanDtype(),\n","    'blurb' : pd.StringDtype(storage='pyarrow'),\n","    'dir_city_id' : pd.StringDtype(storage='pyarrow'),\n","    'dir_city_name' : pd.StringDtype(storage='pyarrow'),\n","    'dir_city_slug' : pd.StringDtype(storage='pyarrow'),\n","    'dir_country_id' : pd.CategoricalDtype(),\n","    'dir_country_name' : pd.CategoricalDtype(),\n","    'lat' : pd.Float32Dtype(),\n","    'lng' : pd.Float32Dtype(),\n","    'primary_alias_on_fb' : pd.StringDtype(storage='pyarrow'),\n","    'slug' : pd.StringDtype(storage='pyarrow'),\n","    'website' : pd.StringDtype(storage='pyarrow'),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5daa9600-2f7b-4b06-8d93-3290f1974535","_uuid":"b74f0c1d-dfc2-4f4d-ae39-668b837a8231","execution":{"iopub.execute_input":"2022-10-27T20:37:45.041673Z","iopub.status.busy":"2022-10-27T20:37:45.041179Z","iopub.status.idle":"2022-10-27T20:37:45.059419Z","shell.execute_reply":"2022-10-27T20:37:45.057484Z","shell.execute_reply.started":"2022-10-27T20:37:45.041617Z"},"trusted":true},"outputs":[],"source":["def get_types(signed=True, unsigned=True, custom=[]):\n","    '''Returns a pandas dataframe containing the boundaries of each integer dtype'''\n","    # based on https://stackoverflow.com/a/57894540/9419492\n","    pd_types = custom\n","    if signed:\n","        pd_types += [pd.Int8Dtype() ,pd.Int16Dtype() ,pd.Int32Dtype(), pd.Int64Dtype()]\n","    if unsigned:\n","        pd_types += [pd.UInt8Dtype() ,pd.UInt16Dtype(), pd.UInt32Dtype(), pd.UInt64Dtype()]\n","    type_df = pd.DataFrame(data=pd_types, columns=['pd_type'])\n","    type_df['np_type'] = type_df['pd_type'].apply(lambda t: t.numpy_dtype)\n","    type_df['min_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).min)\n","    type_df['max_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).max)\n","    type_df['allow_negatives'] = type_df['min_value'] < 0\n","    type_df['size'] = type_df['np_type'].apply(lambda row: row.itemsize)\n","    type_df.sort_values(by=['size', 'allow_negatives'], inplace=True)\n","    return type_df.reset_index(drop=True)\n","def downcast_int(file_path, column:str, chunksize=10000, delimiter=',', signed=True, unsigned=True):\n","    '''Assigns the smallest possible dtype to an integer column of a csv'''\n","    types = get_types(signed, unsigned)\n","    negatives = False\n","    print(delimiter)\n","    for chunk in pd.read_csv(file_path, \n","                             usecols=[column],\n","                             delimiter=delimiter,\n","                             chunksize=chunksize):\n","        M = chunk[column].max()\n","        m = chunk[column].min()\n","        if not signed and not negatives and m < 0 :\n","            types = types[types['allow_negatives']] # removes unsigned rows\n","            negatives = True\n","        if m < types['min_value'].iloc[0]:\n","            types = types[types['min_value'] < m]\n","        if M > types['max_value'].iloc[0]:\n","            types = types[types['max_value'] > M]\n","        if len(types) == 1:\n","            print('early stop')\n","            break\n","    return types['pd_type'].iloc[0]\n","\n","def optimize_cols(file, int_cols, delimiter=',', signed=True, unsigned=True):\n","    out = dict()\n","    for col in int_cols:\n","        out[col] = downcast_int(file, col, delimiter=delimiter, signed=signed, unsigned=unsigned)\n","    return out"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2ccd491e-15a7-42fb-ae90-91bb470a223f","_uuid":"f0909c60-1a13-4d29-825e-3cbec859f267"},"source":["Since the `int` columns are the most used in the research questions, we try to _squeeze_ out each and every useful Byte. As such we perform a further optimization on their dtypes, trying to downcast their `int` dtype to the minimum.\n","\n","    Int8 < Int16 < Int32 < Int64 \n","    \n","As such we wrote some functions that for each `Int64` column previously assigned, reads the values of that column and then returns the smallest possible `IntXX` dtype.\n","\n","---\n","At the end we obtain a substantial reduction of memory usage, **saving around 60 to 70%** from the unoptimized version (note that we estimated this in a sample of the whole dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c42c8da-a03c-43ea-ac01-17331dd8d839","_uuid":"51ffc2f0-1376-42f1-ab0d-1409e6cb1170","execution":{"iopub.execute_input":"2022-10-27T20:37:45.392762Z","iopub.status.busy":"2022-10-27T20:37:45.392226Z","iopub.status.idle":"2022-10-27T20:37:46.474349Z","shell.execute_reply":"2022-10-27T20:37:46.472515Z","shell.execute_reply.started":"2022-10-27T20:37:45.392717Z"},"trusted":true},"outputs":[],"source":["for ds in datasets:\n","    if not ds.load_types():\n","        int_cols = [k for k,v in ds.types.items() if v == 'Int64']\n","        print(int_cols)\n","        ds.types.update(optimize_cols(ds.file_name, int_cols, delimiter='\\t'))\n","        print(f'Optimized {len(int_cols)} types for {ds.name()}')\n","    ds.save_types()\n","\n","for ds in datasets:\n","    ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'], nrows=SAMPLE_SIZE)\n","    avg_mem_unoptimized = pd.read_csv(ds.file_name, index_col='sid', delimiter='\\t', nrows=SAMPLE_SIZE).memory_usage(deep=True).sum()/SAMPLE_SIZE\n","    avg_mem_optimized = ds.df.memory_usage(deep=True).sum()/SAMPLE_SIZE\n","    print(f'{ds.name().ljust(19)} mean optimized memory usage per entry:  {round(avg_mem_optimized):3} B vs {round(avg_mem_unoptimized):4} B  : {round(avg_mem_optimized/avg_mem_unoptimized*100,2):5}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba3fb8ff-c9de-44dc-b9b8-5e25b82834f8","_uuid":"1ba575bf-6341-4baa-9d3c-2d80fde1929b","execution":{"iopub.execute_input":"2022-10-27T20:37:46.477159Z","iopub.status.busy":"2022-10-27T20:37:46.476733Z","iopub.status.idle":"2022-10-27T20:37:46.485529Z","shell.execute_reply":"2022-10-27T20:37:46.483851Z","shell.execute_reply.started":"2022-10-27T20:37:46.477122Z"},"trusted":true},"outputs":[],"source":["for ds in datasets:\n","    print(ds.name())\n","    {print(f\"\\t{k:25}\\t{v}\") for k,v in ds.types.items() if pd.api.types.is_numeric_dtype(v)}"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a5e5bf60-a15d-4491-b0e5-3d2a65b4982f","_uuid":"5cb1e074-e373-4d7e-9b1c-07d3ad118fa2"},"source":["#### Profiles \n","| Field | Description | Type |\n","|---|---|---|\n","| SID | Sequence ID | `int` |\n","| profile_id | Instagrams ID | `int `|\n","| profile_name | profile name | `string` |\n","| firstname_lastname | firstname lastname | `string` |\n","| description | May contain '\\n' | `string` |\n","| following | Number of following profile at the moment it was visited | `int` |\n","| followers | Number of followers at the moment it was visited | `int` |\n","| n_posts | Number of posts at the moment it was visited | `int` |\n","| url | Url in profile description | `string` |\n","| cts | Timestamp when the profile was visited | `datetime` |\n","| is_business_account | Boolean flag if that profile was makred by the owner as business account | `bool` |\n","\n","#### Locations\n","\n","| Field | Description | Type |\n","|---|---|---|\n","| SID | Sequence ID | `int` |\n","| ID | Instagrams ID | `int` |\n","| Name | Locations Name | `string` |\n","| Street | Street Address, may contain '\\n' | `string` |\n","| ZIP | Zip code | `string` |\n","| City | City Name | `string` |\n","| Region | Region | `string` |\n","| CD | Country Code | `string` |\n","| Phone | The phone in format as on the Instragram | `string` |\n","| aj_exact_city_match | The Instagrams Internal key | `bool` |\n","| aj_exact_country_match | The Instagrams Internal key | `bool` |\n","| blurb | Description of the place, may contain '\\n' | `string` |\n","| dir_city_id | The Instagrams internal City ID | `string` |\n","| dir_city_name | city Name | `string` |\n","| dir_city_slug | City tag (sortof) | `string` |\n","| dir_country_id | Country ID | `categorical` |\n","| dir_country_name | country | `categorical` |\n","| lat | Latitude | `float` |\n","| lng | Longtitude | `float` |\n","| primary_alias_on_fb | Bool Flag | `bool` |\n","| slug | ??? | `string` |\n","| website | The URL to web site, may contain more then 1 URL, may contain '\\n' | `string` |\n","| cts | Timestamp when the location was visited | `datetime` |\n","\n","#### Posts\n","| Field | Description | Type |\n","|---|---|---|\n","| SID | Sequence ID | `int` |\n","| sid_profile | Sequence ID of the profile from *Profiles* table, -1 if not in *Profiles* table | `int` |\n","| post_id | Instagrams ID | `string` |\n","| profile_id | Instagrams ID may be null | `int` |\n","| location_id | Instagrams ID | `int` |\n","| cts | Timestamp when the Post was created | `datetime` |\n","| post_type | 1 - Photo, 2 - Video, 3 - multy | `categorical` |\n","| description | May contain '\\n' | `string` |\n","| number_likes | Number of Likes at the moment it was visited | `int` |\n","| number_comments | Number of comments at the moment it was visited | `int` |"]},{"cell_type":"markdown","metadata":{"_cell_guid":"07f06498-5f36-48ad-8b2f-2f9cc3aca638","_uuid":"dbe795ab-8e61-465b-9570-d2be2a49d8b2"},"source":["***\n","\n","### __1. [RQ1] After collecting information, the Data Scientists have to know what dataset they are dealing with, so let's start with an Exploratory Data Analysis (EDA). What can you say about our datasets? Please summarise its main characteristics with visual and tabular methods.__\n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6dfd1c3d-c925-4abb-b1e7-a9a87c7a09e5","_uuid":"c33a3716-5c7b-45ff-b887-3bbf520702fd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"6bf75de8-60e1-400e-99f8-1725993c78d7","_uuid":"8b28e770-9315-427e-9dc8-d248c7844c73"},"source":["***\n","\n","### __2. [RQ2] Let's explore the dataset by finding simple insights regarding the profile and posts.__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2475aaf4-16ec-4032-8533-70114746af84","_uuid":"15fadcb3-7620-4804-9064-3d58556ac9cc"},"source":["#### $\\bullet$ Plot the number of posts for each profile in descending order."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aceadc44-a387-4848-baef-7d1cbffa258e","_uuid":"8c61e74e-bcd3-4fea-a203-9ffac0ab44b8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"312093f3-61fa-45c7-8c36-d91f66933237","_uuid":"d66d6f06-de40-4386-aa9a-0d3b2157e843"},"source":["#### $\\bullet$ What posts have the highest number of \"likes\"?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8207eba5-9588-4524-a9ff-069053ec3c02","_uuid":"15be443e-cb46-493b-80ab-87e363031a62"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"8797868f-f95c-44cf-ad9b-533b281ff20b","_uuid":"f5a09afe-6946-48e5-8f18-819e1c03968f"},"source":["#### $\\bullet$ What posts have the most and the least number of comments?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8e0a72e-894e-4950-86a2-942d777bf482","_uuid":"8f9c80f1-e077-4b13-9af5-7ee86455e02a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"83124266-b414-4c6f-bce4-a318b7d56921","_uuid":"361364ac-ff5b-424c-9018-3464ca82fa90"},"source":["#### $\\bullet$ How many posts include tagged locations, and how many do not? Show it using an appropriate chart and comment your results."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d46fdce-e7c3-429b-9e12-6ef20531eb88","_uuid":"93243cc1-2c05-46d2-b371-fce54ec85966"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"606da32d-efa9-4659-915f-757b4ec50d92","_uuid":"dff39ca5-edc4-448b-a25b-b3ac495ea1c1"},"source":["#### $\\bullet$ How many posts include only photos? How many also have videos?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42465521-682a-4d06-92c0-b35bb99275f9","_uuid":"8e089050-96a2-46cc-8995-14a0f9cd9450"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"024ac001-625a-41eb-8cc6-f01941a8e9e1","_uuid":"c6c7b895-a3cc-482b-9e01-9ebf22b4238f"},"source":["#### $\\bullet$ What's the percentage of business accounts vs non- business? What can you interpret regarding that percentage?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62f405c5-f108-4f0c-b0aa-6c458bde9410","_uuid":"e85de49f-6bfb-4104-a202-597028d3a38b"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"3d95e4ab-3f18-4307-89fa-54236dd9ea95","_uuid":"ac0d7da8-7311-478a-b207-730b6cde3415"},"source":["***\n","\n","### 3. __[RQ3] Now it's important to understand the most common times in which users publish their posts__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"73b8c978-adf9-43c2-a3ce-54d03d1f36f0","_uuid":"cc9debcf-edfd-4ab2-a729-5ee4ed0f3f29"},"source":["#### What is the most common time in which users publish their posts?"]},{"cell_type":"markdown","metadata":{},"source":["I can visualize the most common time by using a radar chart, we can observe that the peak hour for posting is at 19, and in general in the evening."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9ee238c-453b-4e64-9bf8-47343a0e1d70","_uuid":"d8237008-7417-4da2-87b2-78332618b3b9","execution":{"iopub.execute_input":"2022-10-27T15:29:22.949064Z","iopub.status.busy":"2022-10-27T15:29:22.948378Z","iopub.status.idle":"2022-10-27T15:29:25.514014Z","shell.execute_reply":"2022-10-27T15:29:25.512538Z","shell.execute_reply.started":"2022-10-27T15:29:22.948978Z"},"tags":[],"trusted":true},"outputs":[],"source":["time = posts.col(['cts'], index=False, max_nrows=1000000)\n","time['hour'] = time['cts'].dt.hour"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e422ef5-b78c-435e-a1e6-ce0712001bb8","_uuid":"a9dbddb9-7b76-47ce-9876-f784d2e79479","execution":{"iopub.execute_input":"2022-10-27T15:56:23.170359Z","iopub.status.busy":"2022-10-27T15:56:23.169828Z","iopub.status.idle":"2022-10-27T15:56:24.130024Z","shell.execute_reply":"2022-10-27T15:56:24.128442Z","shell.execute_reply.started":"2022-10-27T15:56:23.170319Z"},"tags":[],"trusted":true},"outputs":[],"source":["def cool_ticks(value, tick_number=None):\n","    '''based on https://stackoverflow.com/a/59973033/9419492'''\n","    num_thousands = 0 if abs(value) < 1000 else floor(log10(abs(value))/3)\n","    value = round(value / 1000**num_thousands)\n","    if value >= 1000:\n","        value /= 1000\n","        num_thousands += 1\n","    return f'{value:g}'+' KMGTPEZY'[num_thousands], value * 1000**num_thousands\n","\n","def clock_graph(hours: pd.Series, labels:list=None):\n","    '''plots a Series in a Radar Chart.\n","        :hours: a pandas series where each row index will become an angle\n","    '''\n","    plt.figure(figsize=(7,7))\n","\n","    # https://www.python-graph-gallery.com/390-basic-radar-chart\n","    N = len(hours)\n","    angles = [n / float(N) * 2 * pi for n in range(N)]\n","    angles += angles[:1]\n","    angles = angles[::-1]\n","    hours = pd.concat([\n","        hours.iloc[N//4:],\n","        hours.iloc[:N//4] ]) if N==24 else hours.sort_index(ascending=False)\n","    # Initialise the spider plot\n","    ax = plt.subplot(111, polar=True)\n","\n","    # Draw one axe per variable + add labels\n","    labels = labels if labels is not None else hours.index.map(lambda h: f\"{int(h)}:00\")\n","    plt.xticks(angles[:-1], labels, color='black', size=15)\n","\n","    # Draw ylabels\n","    ax.set_rlabel_position(10)\n","    M = hours.max()\n","    ticks = [cool_ticks(M*x/5) for x in range(1,5)]\n","    plt.yticks([v[1] for v in ticks], [t[0] for t in ticks], color=\"black\", size=10)\n","    plt.ylim(0,M*21/20)\n","    \n","    # Plot data\n","    ax.plot(angles, [*hours, hours.iloc[0]], linewidth=2, linestyle='solid')\n","    hour_max = hours.index.get_loc(hours.idxmax()) if N!=24 else hours.idxmax()-N//4\n","    ax.plot(angles[hour_max],M, 'bo', label=f\"Max: {M}\")\n","\n","    # Fill area\n","    ax.fill(angles[:-1], hours, 'b', alpha=0.1)\n","\n","hours = time.hour.value_counts(sort=False).sort_index().to_frame()\n","\n","clock_graph(hours.hour)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6cfbb2cf-afb8-4eef-a1e1-f30d324c6181","_uuid":"c070f463-8734-43af-b031-885df4a226f0"},"source":["#### $\\bullet$ Create a function that receives a time intervals list as a parameter and returns a plot with the number of posts for each given interval."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba9317a7-ec07-42d7-a56c-7b41ece88cce","_uuid":"2b53a802-006b-4a78-b3f9-62798a07bf22","execution":{"iopub.execute_input":"2022-10-27T15:56:58.667296Z","iopub.status.busy":"2022-10-27T15:56:58.666791Z","iopub.status.idle":"2022-10-27T15:56:58.680501Z","shell.execute_reply":"2022-10-27T15:56:58.679222Z","shell.execute_reply.started":"2022-10-27T15:56:58.667259Z"},"trusted":true},"outputs":[],"source":["def inter(h,intervals:dict):\n","    for k,(m,M) in intervals.items():\n","        if (h >= m and h <= M) or (m>M and (h >= m or h <= M)):\n","            return k\n","    assert False, 'Interval not given: ' + str(h)\n","        \n","def plot_intervals(hours_count, inters=range(0,24,4), col_name='hour'):\n","    \"\"\"A radarplot with the hours divided into intervals\n","    :hours_count: a dataframe where index is the hours\n","    :inters: a sorted list of hours breakpoints, with values between 1 and 24 \n","    :col_name: the column of which the values have to be plotted\n","    \"\"\"\n","    assert min(inters)>0 and max(inters)<=24, 'Values must be included in 1..24'\n","    intervals = { f\"[{inters[i-1]}:00,{inters[i]-1}:59)\" : (inters[i-1],inters[i]-1) for i in range(len(inters)) }\n","    I = pd.CategoricalDtype(categories=intervals.keys() , ordered=True)\n","    hours_count['intervals'] = hours_count.index.to_series().apply(\n","        lambda h :inter(h, intervals)\n","    ).astype(I)\n","    clock_graph(hours_count.groupby(by='intervals').sum()[col_name], labels=I.categories)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"be886c71-a9fa-47d3-8e0c-0adc9c9acf63","_uuid":"5c3a44a8-08e1-4789-a474-44f67a63c1f2"},"source":["#### $\\bullet$ Use the function that you created in the previous literal to plot the number of posts between the following time intervals:\n","\n","| Initial time | Final time |\n","|---|---|\n","| 06:00:00 | 10:59:59 |\n","| 11:00:00 | 13:59:59 |\n","| 14:00:00 | 16:59:59 |\n","| 17:00:00 | 19:59:59 |\n","| 20:00:00 | 23:59:59 |\n","| 00:00:00 | 02:59:59 |\n","| 03:00:00 | 05:59:59 |"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93924e1d-5a2a-456c-b02d-c0fbe2aa48d5","_uuid":"9156018c-4b65-47ed-afbe-68612fb5aae0","execution":{"iopub.execute_input":"2022-10-27T15:57:01.843017Z","iopub.status.busy":"2022-10-27T15:57:01.842512Z","iopub.status.idle":"2022-10-27T15:57:02.441858Z","shell.execute_reply":"2022-10-27T15:57:02.440337Z","shell.execute_reply.started":"2022-10-27T15:57:01.842963Z"},"trusted":true},"outputs":[],"source":["INTERVALS = [3,6,11,14,17,20,24]\n","plot_intervals(hours, INTERVALS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27ca6a09-0e8f-4ef0-883f-e52056d51fa5","_uuid":"3345990c-604e-4878-b2de-b3f7195b9110"},"outputs":[],"source":["del time\n","del hours"]},{"cell_type":"markdown","metadata":{"_cell_guid":"87c581d4-d8e9-4347-8ecd-63948ee638ae","_uuid":"2bbf13f8-20a1-4ca4-8dca-b4ef833356b4"},"source":["***\n","\n","### 4. __[RQ4] In most cases, we will not have a consistent dataset, and the one we are dealing with is not an exception (ex. in the given datasets, you may not find the information of the profiles for some of the posts). So let’s enhance our analysis.__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"0aef0cde-be2d-4ae7-bc1d-341686742431","_uuid":"272eeac9-d54b-433a-9693-6eae3143f2e4"},"source":["#### $\\bullet$ Write a function that, given a profile_id, will be able to return the posts that belong to the given profile_id."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2354c8e8-347f-4d3f-b367-3b4d76c3f0b6","_uuid":"e73be0ba-4506-4666-a1b3-4f937521a868"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"e100455b-d5f0-4b54-9a82-8500a84a5ff4","_uuid":"f2044866-0afc-4569-939c-92433aaf2996"},"source":["#### $\\bullet$ Write another function that, given an input n (an integer), will return the posts that belong to the n top posted profiles (top n profiles that have posted the highest number of posts) that their data is available in the profile.csv using the previously written function."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65266ccc-8305-426b-a6e6-ca9da5d32140","_uuid":"6d6b9f5a-3580-4411-bad6-e57ab6b6e579"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"b4dd6ec7-dd31-48f5-b379-3c7631221eb7","_uuid":"710a4e85-c98e-4924-8c2f-b1e6743b73b4"},"source":["#### $\\bullet$ What is the average number of \"likes\" and comments of the top 10 profiles with the highest number of posts which their information is available in profile.csv?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf05d25e-54f0-4fe5-b86a-4f31f1d478e4","_uuid":"544ba766-9383-4216-a8ae-6ad34b5d9d51"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"eb0e7b84-22eb-4d03-a27b-28cc1fb3d8fd","_uuid":"5a9c21f8-2223-4842-8673-d2cf02140de6"},"source":["#### $\\bullet$ Plot the number of posts that these top 10 profiles have sent on Instagram in the given interval in question RQ3. Interpret the resulting chart."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"104b6d09-404c-4aad-9070-175702c5a91c","_uuid":"438cd3f5-df1a-444a-85b0-d39be7038aaf"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"9678583d-622e-482d-ac75-f9bb142ef9ab","_uuid":"66054368-a856-4aa8-8520-8128dfc85809"},"source":["***\n","\n","### 5. __[RQ5] The most influential users are the ones with the highest number of “followers\", you can now look more into their activity.__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"13512a69-7b9f-4af7-95e2-d98c3a72a857","_uuid":"f28a8d41-565a-4986-bc46-6a159bc2fb77"},"source":["#### $\\bullet$ Plot the top 10 most popular users in terms of followers and their number of posts."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4f48d69-2b7b-4e4c-b6e8-e5da7466cb22","_uuid":"8bd406fa-ba9f-4fac-9c0b-750307d92252"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"e332804e-0378-4e36-b58f-61400a32db44","_uuid":"6aa6da1a-473b-4a71-9c7d-3e29e1a5632a"},"source":["#### $\\bullet$ Who is the most influential user?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc9e1a0b-99d0-42d7-bcfd-0c08d1e68dc8","_uuid":"034a9faf-0a47-432d-abeb-64d6f0042791"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"8aa98e6d-355a-445c-8158-82c54f80e66c","_uuid":"20ee477b-14d2-42e1-ba0d-7be3698b7d59"},"source":["#### $\\bullet$ Have they posted anything with tagged locations? Extract the most frequent areas on their posts and plot the number of times each city has been visited."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54d41e8e-471d-45de-8ece-f966bb9dacbc","_uuid":"bb6b752b-a054-4436-abc7-96f1274f1f43"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"1b0a9858-b38e-4a92-91de-aad5356cba86","_uuid":"7c6c7102-9ba6-49bb-948f-f2950a6085bd"},"source":["#### $\\bullet$ How many pictures-only posts have they published? How many reels? (only videos) and how many with both contents? Provide the number as percentages and interpret those figures."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cff1580-f399-4c6d-94e4-2804b13cad85","_uuid":"31688fda-85cb-4652-ac3a-cd6ed8adaa30"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"c3b5295b-380c-44da-a65c-03ab1f79f7f2","_uuid":"a54068bc-e6a3-40e7-af97-8613f4c5f65c"},"source":["#### $\\bullet$ How many \"likes\" and comments did posts with only pictures receive? How about videos and mixed posts? Try to provide the average numbers and confront them with their followers amount, explaining what you can say from that comparison."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d2119ef-cf6b-4202-81ce-46f9a1e9815e","_uuid":"db886faf-6b9a-4f6d-961e-4f933794c69b"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"69a88e3e-6b19-466c-92f8-73721660e103","_uuid":"303e7021-97ad-408c-ac10-bba6540dda21"},"source":["### 6. __[RQ6] It's time to get information from the user posting effectiveness.__"]},{"cell_type":"markdown","metadata":{"_cell_guid":"587eb1a4-1d2e-4c6c-a77e-cb789f38b3d8","_uuid":"6780ebd7-940c-4ea5-97b5-f70ed3a06849"},"source":["#### What is the average time (days and minutes) a user lets pass before publishing another post? Plot the top 3 users that publish posts more frequently (calculate the average time that passes between posts), including their amount of followers and following. Provide insights from that chart."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec58c250-acb2-4fa0-8750-a48c268bbb8d","_uuid":"b5618895-1969-4a97-88cc-1f95a3ecfbb7","execution":{"iopub.execute_input":"2022-10-27T22:16:01.042196Z","iopub.status.busy":"2022-10-27T22:16:01.040669Z","iopub.status.idle":"2022-10-27T22:38:39.932074Z","shell.execute_reply":"2022-10-27T22:38:39.928711Z","shell.execute_reply.started":"2022-10-27T22:16:01.042136Z"},"trusted":true},"outputs":[],"source":["# TODO maybe it's better to load \n","    # 'sid_profile' since it's of int type and can be connected to profiles table\n","    # 'profile_id' since it includes all profiles id (less null?) and otherwise most of the values get smashed into -1\n","drift = lambda g: (g.max() - g.min()) / (g.count()-1) if g.shape[0] > 1 else pd.NA\n","\n","post_time = posts\\\n","                .col(['profile_id','sid_profile','cts'], index=None)\\\n","                .groupby(by=['profile_id','sid_profile'], sort=False, dropna=True)\\\n","                .aggregate(\n","                        drift=pd.NamedAgg(column=\"cts\", aggfunc=drift),\n","                        count=pd.NamedAgg(column=\"cts\", aggfunc=\"count\"))\\\n","                .dropna()\n","post_time = post_time[post_time.index.get_level_values('sid_profile') != -1]\n","post_time['drift'] = post_time['drift'].astype('timedelta64[ns]')\n","post_time.head()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"7f1b9b41-23a0-4e4f-a201-93b8e90a3f4d","_uuid":"b2a63656-c10a-47f2-aefe-292ab8989598"},"source":["We want to note that this kind of metric, as taken by itself alone, has **little or no value** since it doesn't take in account the number of posts, and it's not robust at all.\n","\n","For example it could happen that people that have posted only a couple of times in a small interval of time are labeled as the most frequent post publishers."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d4be03a-03aa-4a8c-8144-8546c81ecc70","_uuid":"c9d146bd-6ef9-46dd-82a1-0113c3d83fb7","execution":{"iopub.execute_input":"2022-10-27T22:38:39.940581Z","iopub.status.busy":"2022-10-27T22:38:39.939932Z","iopub.status.idle":"2022-10-27T22:38:55.763460Z","shell.execute_reply":"2022-10-27T22:38:55.760064Z","shell.execute_reply.started":"2022-10-27T22:38:39.940522Z"},"trusted":true},"outputs":[],"source":["N3 = 3 # 100\n","post_time = post_time[\n","    post_time.index.get_level_values('sid_profile') != -1\n","]\n","posters =  post_time\\\n","            .droplevel('profile_id')\n","posters = posters[~posters.index.duplicated(keep='first')]\n","\n","posters = pd.concat([\n","    posters,\n","    profiles.col(['followers', 'following'], index=True).dropna()\n","], axis=1, join='inner')\n","posters.nsmallest(3, columns='drift')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5826b5ce-2271-425b-8cdc-476f6bd87723","_uuid":"d25f63e5-00cd-4c9b-afdc-8a5a708ebb00"},"source":["Here I plot on a graph the first 3 top frequency post publishers (excluding those that do not have a following/followers infos)\n","\n","I honestly do not get any insight from this graph because:\n","- 3 isn't enough to get any useful insights\n","- this frequency measure we're taking in is not robust at all, and shouldn't be considered into account (for the aforementioned reasons)\n","- even when plotting much more points, the plot doesn't show any correlation between drift and the other two features\n","- some of the elements have $T = 0$, meaning that it may have happened that some posts have been posted in the exact same moment by the same account $frequency = \\frac{1}{T} = \\infty$"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e081f51-1501-4836-9626-09ae5b5df78f","_uuid":"8f5a8ce2-bd05-4cce-bf50-30f90ffadd41","execution":{"iopub.execute_input":"2022-10-27T22:38:55.770350Z","iopub.status.busy":"2022-10-27T22:38:55.768811Z","iopub.status.idle":"2022-10-27T22:39:11.378136Z","shell.execute_reply":"2022-10-27T22:39:11.376718Z","shell.execute_reply.started":"2022-10-27T22:38:55.770282Z"},"trusted":true},"outputs":[],"source":["posters = posters[posters.drift > pd.Timedelta(seconds=1)]\n","ax = sns.histplot(\n","    x=posters.drift.dt.total_seconds()/3600,\n","    log_scale=True,\n","    bins=40,\n","    kde=True, \n","    palette='pastel')\n","ax.set(\n","    title='Average hours between posts per user',\n","    xlabel='',\n","    yscale='log',\n","    ylabel='Occurences'\n",")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We note that there are some users that tend to post very very often, as in fact we note a small bump when the x-axis is around $10^{-2} hours \\sim 36s$. This denotes all those profiles that tend to post at an unhuman frequency, and may indicate errors in the dataset or that the profile is operated by a bot.\n","\n","And now, the requested Mondrian painting:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T22:39:11.952475Z","iopub.status.busy":"2022-10-27T22:39:11.951998Z","iopub.status.idle":"2022-10-27T22:39:12.783774Z","shell.execute_reply":"2022-10-27T22:39:12.782081Z","shell.execute_reply.started":"2022-10-27T22:39:11.952432Z"},"trusted":true},"outputs":[],"source":["top3 = posters.nsmallest(3, columns='drift')\n","ax = sns.scatterplot(data=top3,\n","                x=\"following\", \n","                y=\"followers\", \n","                hue=3600/top3['drift'].dt.total_seconds(), \n",")\n","ax.legend(title='Posts per hour')\n","ax.set(\n","    title='Average number of posts per hour - TOP3',\n","    yscale='log',\n","    xscale='log'\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-10-27T23:03:41.887386Z","iopub.status.idle":"2022-10-27T23:03:41.888198Z","shell.execute_reply":"2022-10-27T23:03:41.887981Z","shell.execute_reply.started":"2022-10-27T23:03:41.887953Z"},"trusted":true},"outputs":[],"source":["ax = sns.scatterplot(data=posters,\n","                x=\"following\", \n","                y=\"followers\", \n","                hue=3600/posters['drift'].dt.total_seconds(), \n","                alpha=0.9)\n","ax.legend(title='Posts per hour')\n","ax.set(\n","    title='Average number of posts per hour',\n","    yscale='log',\n","    xscale='log'\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T23:12:16.805500Z","iopub.status.busy":"2022-10-27T23:12:16.804979Z"},"trusted":true},"outputs":[],"source":["posters_no_outliers = posters[posters.drift.between(\\\n","                                                   posters.drift.quantile(0.1),\n","                                                   posters.drift.quantile(0.9))]\n","\n","ax = sns.kdeplot(data=posters_no_outliers,\n","                x=\"count\" ,\n","                y=posters_no_outliers.drift.dt.total_seconds(), \n","                palette=\"pastel\",\n","                shade=True,\n","                cbar=True)\n","ax.set(\n","    title=\"Correlation between number of posts and periods between posts\",\n","#     yscale='log',\n","#     xscale='log'\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6799883c-06fb-451a-a600-da286c30d301","_uuid":"97c3acbc-af40-41bf-b362-1a2bfc229aa0","execution":{"iopub.execute_input":"2022-10-24T20:27:53.763220Z","iopub.status.busy":"2022-10-24T20:27:53.761933Z","iopub.status.idle":"2022-10-24T20:27:53.768402Z","shell.execute_reply":"2022-10-24T20:27:53.767229Z","shell.execute_reply.started":"2022-10-24T20:27:53.763168Z"}},"outputs":[],"source":["del drift \n","del post_time"]},{"cell_type":"markdown","metadata":{"_cell_guid":"9f29409a-a137-4a30-82ba-69da1888b819","_uuid":"e73ffe60-9b82-44ec-885f-a234ecf01dd8"},"source":["#### Using the function you previously coded, plot the time intervals with the highest average number of “likes” and the ones with the highest average number of comments on posts."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dacac989-b36b-40f1-be82-49a136cf5479","_uuid":"d4f6643d-ec0f-4dd8-808d-322be2d26f78","execution":{"iopub.execute_input":"2022-10-25T11:01:44.859709Z","iopub.status.busy":"2022-10-25T11:01:44.858941Z","iopub.status.idle":"2022-10-25T11:02:42.418001Z","shell.execute_reply":"2022-10-25T11:02:42.416069Z","shell.execute_reply.started":"2022-10-25T11:01:44.859621Z"}},"outputs":[],"source":["likes_time = posts.col(['numbr_likes', 'number_comments', 'cts'], index=False)\n","likes_time['hour'] = likes_time['cts'].dt.hour\n","likes_time.drop('cts', inplace=True, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d586cf93-7c66-4899-bc1b-cb490f043f3a","_uuid":"76d0342b-b764-4922-adfd-fd680ffa39a9","execution":{"iopub.execute_input":"2022-10-25T11:02:42.420011Z","iopub.status.busy":"2022-10-25T11:02:42.419614Z","iopub.status.idle":"2022-10-25T11:02:44.140544Z","shell.execute_reply":"2022-10-25T11:02:44.139719Z","shell.execute_reply.started":"2022-10-25T11:02:42.419979Z"}},"outputs":[],"source":["plot_intervals(likes_time.groupby(by='hour').agg('mean'), INTERVALS, col_name='numbr_likes')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"754dae71-e7fc-48d0-89c6-18fc0558e785","_uuid":"52b3f658-72c7-40b5-b56c-171f9bd7e7dd","execution":{"iopub.execute_input":"2022-10-25T11:02:44.142350Z","iopub.status.busy":"2022-10-25T11:02:44.141726Z","iopub.status.idle":"2022-10-25T11:02:45.773169Z","shell.execute_reply":"2022-10-25T11:02:45.772113Z","shell.execute_reply.started":"2022-10-25T11:02:44.142316Z"}},"outputs":[],"source":["plot_intervals(likes_time.groupby(by='hour').agg('mean'), INTERVALS, col_name='number_comments')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8cffc47-e74d-44e2-97fc-918b3e0c0f1c","_uuid":"92a5258f-3a98-44de-9979-16e5f9e4f1da","execution":{"iopub.execute_input":"2022-10-24T18:51:31.345659Z","iopub.status.busy":"2022-10-24T18:51:31.344897Z","iopub.status.idle":"2022-10-24T18:51:31.368113Z","shell.execute_reply":"2022-10-24T18:51:31.366725Z","shell.execute_reply.started":"2022-10-24T18:51:31.345613Z"}},"outputs":[],"source":["del likes_time"]},{"cell_type":"markdown","metadata":{"_cell_guid":"79c6a886-ec1d-4bdf-a01a-21fa2e926bf2","_uuid":"6f47e4ef-02ac-4d03-b13c-a8d9141d53b3"},"source":["#### 7. __[RQ7] Of course, calculating probabilities is a job that any Data Scientist must know. So let's compute some engaging figures__"]},{"cell_type":"markdown","metadata":{"_cell_guid":"840a5bc0-37cc-4e20-b356-5c33fd636ed1","_uuid":"0614c246-0c81-483c-88e1-83fdfbf162bb"},"source":["#### $\\bullet$ What's the probability that a post receives more than 20% \"likes\" of the number of followers a user has?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8abb8a0-42f0-4440-8b38-7a6b95ccc434","_uuid":"7b1f9405-c22f-4feb-b433-0743f5436652"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"a6bfb1bb-fd07-4115-9c06-7736dc7813ca","_uuid":"159a8fd8-19ba-48e0-a474-0166352adf80"},"source":["#### $\\bullet$ Do users usually return to locations? Extract the probability that a user returns to a site after having posted it in the past. Does that probability make sense to you? Explain why or why not."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e4dc981-b7df-46da-9958-69b1c1ac0730","_uuid":"82a4c987-e823-4df9-8baf-d5d39233cf23"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"0e35f85a-c782-4667-9e33-202ccf572459","_uuid":"6d219437-2f34-455c-afaa-b0bb82102232"},"source":["### 8. __[RQ8] Every decision you take in a data-based environment should be reinforced with charts, statistical tests and analysis methods to check whether a hypothesis is correct or not.__"]},{"cell_type":"markdown","metadata":{"_cell_guid":"80db8cf9-e2d1-4f83-b9db-d9b555e7358e","_uuid":"4889ba73-069e-4df7-bb0a-62e890255a8e"},"source":["#### $\\bullet$ Does more “likes” also mean more comments? Plot a scatter plot of “likes” vs comments for posts."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55c1f416-4204-4591-97ab-6f8bee04c871","_uuid":"a0ba399a-f3a0-4f2a-9f9d-d034101d1086"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"4cadc12a-aa17-4d1d-9c86-30e680f1a7ad","_uuid":"750e6003-9fed-4f5b-8bc0-bced433c021f"},"source":["#### $\\bullet$ Can you find any significant relationship between the time a user publishes a post and the number of comments and “likes”? Use an appropriate statistical test or technique and support your choice."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0119fc48-5a32-4f04-9ca9-47be28446104","_uuid":"1f37cda6-27c4-483d-a187-6efb464b7ce1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"61224850-a5b5-408f-96b1-fc2fdd23ec4b","_uuid":"5bf5c68a-44cf-4302-9675-59c8cf465d89"},"source":["#### $\\bullet$ What’s the distribution of followers? Plot the empirical distribution of followers amongst all users and extract the mean, mode, and quantiles. Interpret those figures."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea486674-3de2-4a70-b479-eb8f54ebecdb","_uuid":"2e59763c-a757-44d1-8f4b-21aca0d3b3be"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"7f82a825-ae1b-4114-8457-4ea0c4e23c14","_uuid":"4dff31e2-8daa-45fa-8e75-f442fdb450ae"},"source":["#### $\\bullet$ What are histograms, bar plots, scatterplots and pie charts used for?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aba72605-290d-4fe7-a5b1-24ff823d1bde","_uuid":"ac72a5f5-b63a-46cd-a036-6d680ebb669d"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"cf5d935e-875b-4105-bd8c-d20b90585532","_uuid":"fcf9aad2-40da-46e9-b6eb-56a07d9a47d9"},"source":["#### $\\bullet$ What insights can you extract from a Box Plot?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40f366e1-ed6d-449f-94ef-afa4d8a72bb0","_uuid":"635b7a04-2a4b-4e9c-a145-1c173aba862a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"a94d21ba-f971-4710-88a7-54c6bf087c24","_uuid":"5bba1f4d-d3f8-4c3d-b777-41823b11624f"},"source":["***\n","\n","## __Bonus points__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"bd7d3745-9a61-4649-b51b-8267cacc8186","_uuid":"8ab9fe93-a18d-411b-b33d-8d0205c40db3"},"source":["#### Up to this point, you probably have worked with one or two files simultaneously. Nevertheless, for the literals a. and b. of this section, you must work with the three datasets at the same time. Note that performing some of these operations might be too complex for your pc specs. For this reason, we suggest you make use of AWS (yeah! only a suggestion). In case you need it, in the following links you can find the same three files already mounted into AWS for you to work with them easily (instagram_posts, instagram_profiles, instagram_locations)."]},{"cell_type":"markdown","metadata":{"_cell_guid":"3a6804c1-f32d-492a-a1b1-8216aeea7866","_uuid":"3fba3dc7-6054-4ef3-9113-c38e6ed32c4b"},"source":["#### a. Sort the users in terms of number of followers and divide them into two groups: for the first group, take only the top 10% regarding \"followers\", and for the second one, take the rest. Now compare the mean of time intervals between posts for the two categories. Do you notice something relevant?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41ce369f-9759-421e-9b70-ce55e25a62a1","_uuid":"43a3e699-118d-40cf-be7f-92d0ebccf894","execution":{"iopub.execute_input":"2022-10-25T09:07:01.875548Z","iopub.status.busy":"2022-10-25T09:07:01.875164Z","iopub.status.idle":"2022-10-25T09:07:11.633861Z","shell.execute_reply":"2022-10-25T09:07:11.632783Z","shell.execute_reply.started":"2022-10-25T09:07:01.875515Z"}},"outputs":[],"source":["profiles.df = profiles.col(['followers'], index=True).dropna()\n","profiles.df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:20:51.134767Z","iopub.status.busy":"2022-10-25T09:20:51.134290Z","iopub.status.idle":"2022-10-25T09:33:05.696389Z","shell.execute_reply":"2022-10-25T09:33:05.694623Z","shell.execute_reply.started":"2022-10-25T09:20:51.134725Z"}},"outputs":[],"source":["drift = lambda g: (g.max() - g.min()) / (g.count()-1) if g.shape[0] > 1 else pd.NA\n","\n","post_time = posts\\\n","                .col(['sid_profile','cts'], index=None)\\\n","                .groupby(by=['sid_profile'], sort=False, dropna=True)\\\n","                .agg(drift=pd.NamedAgg(column=\"cts\", aggfunc=drift))\\\n","                .dropna()\n","post_time = post_time[post_time.index.get_level_values('sid_profile') != -1]\n","post_time['drift'] = post_time['drift'].astype('timedelta64[ns]')\n","post_time.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:33:05.699390Z","iopub.status.busy":"2022-10-25T09:33:05.699038Z","iopub.status.idle":"2022-10-25T09:33:06.291221Z","shell.execute_reply":"2022-10-25T09:33:06.290322Z","shell.execute_reply.started":"2022-10-25T09:33:05.699361Z"}},"outputs":[],"source":["profiles.df = pd.concat([\n","    post_time,\n","    profiles.df[['followers']]\n","], axis=1, join='inner')\n","profiles.df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:33:06.293024Z","iopub.status.busy":"2022-10-25T09:33:06.292523Z","iopub.status.idle":"2022-10-25T09:33:06.305788Z","shell.execute_reply":"2022-10-25T09:33:06.304530Z","shell.execute_reply.started":"2022-10-25T09:33:06.292994Z"}},"outputs":[],"source":["profiles.df['category'] = pd.qcut(profiles.df.followers, [0.,0.9,1.], labels=['norm', 'influencer'])\n","\n","print('Influencers mean time between posts: \\t', profiles.df[profiles.df.category=='influencer'].drift.mean())\n","print('Normal users mean time between posts: \\t', profiles.df[profiles.df.category=='norm'].drift.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:33:06.308515Z","iopub.status.busy":"2022-10-25T09:33:06.308031Z","iopub.status.idle":"2022-10-25T09:33:06.604535Z","shell.execute_reply":"2022-10-25T09:33:06.602772Z","shell.execute_reply.started":"2022-10-25T09:33:06.308484Z"}},"outputs":[],"source":["sns.set(rc={'figure.figsize':(5,5)})\n","\n","ax = sns.boxplot(data=profiles.df, \n","            x='category', \n","            y=24*31*3600/profiles.df['drift'].dt.total_seconds(), \n","            palette='pastel')\n","ax.set(\n","    xlabel = 'Followers',\n","    ylabel = 'Average posts per month',\n","    title = 'Normal users vs Influencers publishing ratio',\n","    yscale = 'log')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:33:06.606642Z","iopub.status.busy":"2022-10-25T09:33:06.606280Z","iopub.status.idle":"2022-10-25T09:33:06.611599Z","shell.execute_reply":"2022-10-25T09:33:06.610572Z","shell.execute_reply.started":"2022-10-25T09:33:06.606612Z"}},"outputs":[],"source":["del post_time\n","del profiles.df"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f315c749-e99c-4a4a-a44d-2cce25ebad48","_uuid":"7ca70f05-f21a-454c-9153-d920606647e0"},"source":["#### b. Assume users publish their posts the same day pictures or videos are taken: Are there users that have visited the same location on the same day? How about the same week? Extract the results and explain them."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e6263d0-ff3d-4fb4-91be-bdb3ac3adcb4","_uuid":"0486b05f-5ae1-43a0-921c-98838f8cd705","execution":{"iopub.execute_input":"2022-10-25T09:33:06.613210Z","iopub.status.busy":"2022-10-25T09:33:06.612871Z","iopub.status.idle":"2022-10-25T09:37:32.433491Z","shell.execute_reply":"2022-10-25T09:37:32.432129Z","shell.execute_reply.started":"2022-10-25T09:33:06.613176Z"}},"outputs":[],"source":["posts.df = posts\\\n","    .col(['location_id', 'profile_id', 'cts'])\\\n","    .dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:37:32.435128Z","iopub.status.busy":"2022-10-25T09:37:32.434861Z","iopub.status.idle":"2022-10-25T09:38:24.307960Z","shell.execute_reply":"2022-10-25T09:38:24.306580Z","shell.execute_reply.started":"2022-10-25T09:37:32.435102Z"}},"outputs":[],"source":["day = posts.df\\\n","            .groupby([pd.Grouper(key=\"cts\", freq=\"1d\"), 'location_id', 'profile_id'], sort=False)\\\n","            .agg(cnt=pd.NamedAgg(column=\"cts\", aggfunc='count'))['cnt']\\\n","            .value_counts().sort_index()\n","sns.set(rc={'figure.figsize':(day.index.shape[0]/4,4)})\n","ax = sns.barplot(x=day.index, y=day, palette='pastel')\n","ax.set(\n","    xlabel = '# of posts in the same day and location',\n","    ylabel = 'Occurrences',\n","    title = 'Frequency of same-location posts per Day',\n","    yscale = 'log'\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:38:24.309934Z","iopub.status.busy":"2022-10-25T09:38:24.309616Z","iopub.status.idle":"2022-10-25T09:39:13.836560Z","shell.execute_reply":"2022-10-25T09:39:13.835159Z","shell.execute_reply.started":"2022-10-25T09:38:24.309904Z"}},"outputs":[],"source":["week = posts.df\\\n","            .groupby([pd.Grouper(key=\"cts\", freq=\"1W\"), 'location_id', 'profile_id'], sort=False)\\\n","            .agg(cnt=pd.NamedAgg(column=\"cts\", aggfunc='count'))['cnt']\\\n","            .value_counts().sort_index()\n","sns.set(rc={'figure.figsize':(week.index.shape[0]/4,4)})\n","ax = sns.barplot(x=week.index, y=week, palette='pastel')\n","ax.set(\n","    xlabel = '# of posts in the same week and location',\n","    ylabel = 'Occurrences',\n","    title = 'Frequency of same-location posts per Week',\n","    yscale = 'log'\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-25T09:43:17.202685Z","iopub.status.busy":"2022-10-25T09:43:17.201693Z","iopub.status.idle":"2022-10-25T09:43:17.248428Z","shell.execute_reply":"2022-10-25T09:43:17.246468Z","shell.execute_reply.started":"2022-10-25T09:43:17.202634Z"}},"outputs":[],"source":["del posts.df"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6cec3cc8-369f-4776-82f2-63f1003923a3","_uuid":"abb81736-72fa-4f91-bf86-9603d99a9cdd"},"source":["#### c. Implement a text data analysis (also known as text mining) of the field \"description\" from instagram_posts.csv for descriptions written in English. Use appropriate visualizations and statistics to highlight the words (and probably the topics) provided for the users in that field."]},{"cell_type":"markdown","metadata":{},"source":["The `langdetect` package uses a pretrained machine learning algorithm that supports 55 languages. Given any string it returns the closest match (if possible)."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"441a068b-2566-4a74-94e4-053e36dd33c8","_uuid":"39be287b-88aa-4b1f-a8e7-5cf6db36b9e9","execution":{"iopub.execute_input":"2022-10-27T18:53:37.916711Z","iopub.status.busy":"2022-10-27T18:53:37.916275Z","iopub.status.idle":"2022-10-27T18:53:48.657235Z","shell.execute_reply":"2022-10-27T18:53:48.655912Z","shell.execute_reply.started":"2022-10-27T18:53:37.916676Z"},"trusted":true},"outputs":[],"source":["%pip install langdetect\n","from langdetect import detect\n","\n","detect('Questa libreria identifica la lingua usata!')"]},{"cell_type":"markdown","metadata":{},"source":["Some of the strings may be too short for recognition, so we discard them. Also some strings may be composed of emojis only or mostly and those will give an error when passed to the `detect` function, so we enclose it in a `try-catch` statement."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T19:11:47.377844Z","iopub.status.busy":"2022-10-27T19:11:47.377450Z"},"trusted":true},"outputs":[],"source":["# Remove emojis and newlines\n","EMOJIS = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               u\"\\U0001f926-\\U0001f937\"\n","                               u\"\\U00010000-\\U0010ffff\"\n","                               u\"\\u2640-\\u2642\"\n","                               u\"\\u2600-\\u2B55\"\n","                               u\"\\u200d\"\n","                               u\"\\u23cf\"\n","                               u\"\\u23e9\"\n","                               u\"\\u231a\"\n","                               u\"\\ufe0f\"  # dingbats\n","                               u\"\\u3030\"\n","                               \"#@%\"\n","                               \"0-9\"\n","                                \"]+\", flags=re.UNICODE)\n","\n","def safe_detect(s, minsize=6):\n","    try:\n","        return detect(s)\n","    except:\n","        return pd.NA        \n","\n","lang_share = pd.Series(dtype='Int32')\n","word_frequency = pd.Series(dtype='Int64')\n","for chunk in posts.col(['description'], index=False, pandas=True, chunksize=100000):\n","    chunk.dropna(inplace=True)\n","    chunk.description = chunk.description.str.replace(EMOJIS, '', regex=True).replace(r'\\\\n', '', regex=True) \n","    chunk = chunk[chunk.description.str.len() > 6]\n","\n","    lang_chunk = chunk.description.apply(safe_detect)\n","    lang_share = lang_share.add(lang_chunk.value_counts(), fill_value=0)\n","    \n","    english_descr = chunk.description[lang_chunk == 'en']\\\n","                        .str.extractall(r' (\\w+)')\\\n","                        .reset_index(drop=True)\\\n","                        .value_counts()\n","    english_descr.index = english_descr.index.get_level_values(0)\n","    word_frequency = word_frequency.add(english_descr, fill_value=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T18:53:58.399912Z","iopub.status.busy":"2022-10-27T18:53:58.399380Z","iopub.status.idle":"2022-10-27T18:53:58.409028Z","shell.execute_reply":"2022-10-27T18:53:58.408199Z","shell.execute_reply.started":"2022-10-27T18:53:58.399864Z"},"trusted":true},"outputs":[],"source":["lang_share.sort_values(ascending=False, inplace=True)\n","lang_share.head()"]},{"cell_type":"markdown","metadata":{},"source":["Most common languages:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T18:24:13.457675Z","iopub.status.busy":"2022-10-27T18:24:13.456742Z","iopub.status.idle":"2022-10-27T18:24:14.264739Z","shell.execute_reply":"2022-10-27T18:24:14.262889Z","shell.execute_reply.started":"2022-10-27T18:24:13.457609Z"},"trusted":true},"outputs":[],"source":["g = sns.barplot(\n","    x=lang_share.index,\n","    y=lang_share,\n","    palette='pastel')\n","sns.set(rc={'figure.figsize':(.6*lang_share.count(),5)})\n","g.set(\n","    title='Post descriptions per language',\n","    yscale='log',\n","    ylabel='occurences'\n",")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["`WordCloud` is a graphic library that helps you plot the most prominent words in a text to a Tag Cloud graph. After filtering out some of the words as Stopwords and selecting only the columns in english language, we are able to plot the most used words in english descriptions. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T18:43:19.765530Z","iopub.status.busy":"2022-10-27T18:43:19.763703Z","iopub.status.idle":"2022-10-27T18:43:19.774088Z","shell.execute_reply":"2022-10-27T18:43:19.771943Z","shell.execute_reply.started":"2022-10-27T18:43:19.765445Z"},"trusted":true},"outputs":[],"source":["from wordcloud import WordCloud, STOPWORDS\n","import string\n","STOPWORDS = set(STOPWORDS)\n","STOPWORDS.update({c for c in string.printable})\n","STOPWORDS.update({'ve', 'll', 're'})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-27T18:45:40.814847Z","iopub.status.busy":"2022-10-27T18:45:40.814203Z","iopub.status.idle":"2022-10-27T18:46:00.708732Z","shell.execute_reply":"2022-10-27T18:46:00.707557Z","shell.execute_reply.started":"2022-10-27T18:45:40.814793Z"},"trusted":true},"outputs":[],"source":["wordcloud = WordCloud(\n","    width=2000, \n","    height=2000, \n","    margin=0, \n","    stopwords=STOPWORDS, \n","    background_color='black', \n","    colormap='Pastel1',\n","    scale=2\n",").generate_from_frequencies(word_frequency.to_dict())\n","\n","plt.figure( figsize=(20,20) )\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")\n","plt.margins(x=0, y=0)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In order to analyze the results I would split it in some groups:\n","- Day : `day, today, now` : Many words refer to the current day meaning that this descriptions might have been used to refer and talk about the present events. This might point to a usage of descriptions (and Instagram) to talk and express feelings, as a way to interact with the world.\n","- Positives : `love, friend, thank, happy, life, beautiful` : There are many words that refer to the 'positive-thinking' sphere, meaning that users tend to post mainly positive moments about themselves and their surroundings. This may confirm the known trend of users being biased towards showing out only the best about their lives, trend that may contribute to the increasing problem of mental health and wellbeing, as many instagram users often associate it with high levels of anxiety, depression, bullying, unreachable body and living standards [$^1$](https://www.rsph.org.uk/about-us/news/instagram-ranked-worst-for-young-people-s-mental-health.html)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del descr\n","del english_descr"]},{"cell_type":"markdown","metadata":{"_cell_guid":"dcf46443-7509-46b0-a565-5c992360420e","_uuid":"2f9ac283-9d23-48e7-9e98-dd8b4fc39956"},"source":["***\n","\n","## __Command Line Question__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"22fdbbe3-919a-4c0c-8386-24bc89eb1c4c","_uuid":"3c47106c-987f-4ce5-9ce4-76b9f92fa29b"},"source":["#### Using the command line is a feature that Data Scientists must master. It is relevant since the operations there require less memory to use in comparison to other interfaces. It also does not use as much CPU processing time as other interfaces. In addition, it can be faster and more efficient and handle repetitive tasks quickly."]},{"cell_type":"markdown","metadata":{"_cell_guid":"4eea7c38-b343-410c-9085-74cd750bc017","_uuid":"a494bf00-d29d-4cc3-9d1d-321497582c02"},"source":["#### In this question, you should use command line tools such as grep and possibly other commands to answer the following question:"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2e0f48e8-786d-46db-9e6f-c938815afa03","_uuid":"56e3f479-7f58-4156-bfef-cdfcca643594"},"source":["#### $\\bullet$ Using the instagram_posts.csv, retrieve the first ten posts with descriptions longer than 100 characters and output the profiles that posted them. (Please keep in mind that the profile associated with some of those posts may not be found in the profiles. You can simply output User was not found! for those posts.)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"48781d5b-92a8-4856-8e63-ce716280b680","_uuid":"98cd48e8-8012-4de4-abbf-1061c93d1ca0"},"source":["#### Note: You may work on this question in any environment (AWS, your PC command line, Jupyter notebook, etc.), but the final script must be placed in CommandLine.sh, which must be executable."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8804ce20-253c-4777-8cb9-78ce2be13e93","_uuid":"98753ec5-0c1d-4fb9-8e8f-44b7300e554a"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"35126ecc-b1ef-45d2-8ebe-1348fdaafb36","_uuid":"28cf7a87-cb7d-4521-b397-abed79f109fe"},"source":["***\n","\n","## __Algorithmic Question__\n","\n","***"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6d97c5e2-5af4-4cf6-b4ab-432f4427025a","_uuid":"25cd4852-599e-4093-99b3-ce42d09f60ef"},"source":["### 1. __[AQ1] Given the following pseudocode, answer the questions:__"]},{"cell_type":"markdown","metadata":{"_cell_guid":"59f4244f-ab3c-4361-a8cf-748dab19d12d","_uuid":"440cfd9a-ac5a-4dd6-b289-bcfe98490ae1"},"source":["'''\n","Input:\n","       N : an integer\n","       List : array of characters of leng\n","   function f1(sequence, end):\n","       For i=0 To end:\n","           OUTPUT sequence[i]\n","       EndFor\n","Output \"\\n\"\n","   function f2(sequence, start, end):\n","       If start = end:\n","           f1(sequence, end)\n","       Else\n","           For i=start To end:\n","               temp <-- sequence[start]\n","               sequence[start] <-- sequen\n","               sequence[i] <-- temp\n","               f2(sequence, start+1, end)\n","               temp <-- sequence[start]\n","               sequence[start] <-- sequen\n","               sequence[i] <-- temp\n","   f2(List, 0, N)\n","'''"]},{"cell_type":"markdown","metadata":{"_cell_guid":"ddd603cf-9715-4ed9-91ab-d4381f9fee80","_uuid":"50d5ca7c-7db9-4b68-979c-95eb48ebd228"},"source":["#### $\\bullet$ What is the output of this algorithm? Describe the mechanism of the algorithm in detail . We do not want to know only its final result. (Describe one example on your own)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ad9fe0c-ab24-44e4-b643-98ecfa3a788b","_uuid":"1d8a66b8-3f42-4c32-b69d-a4bd50ba0d9f"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"9edabc2a-aacb-4803-bdc0-02a3cae546b9","_uuid":"59bc1724-a61f-4e55-b9ec-b9b209c3ff1d"},"source":["#### $\\bullet$ What is asymptotically (i.e., we are asking for big-O complexity) the algorithm's running time as a function of N?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e3fb1e2-d523-4a90-a723-710b41979045","_uuid":"47609f92-2687-4e2d-aa41-ad38d4b925f2"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"73bd66ba-ab79-4d23-8c88-2b40b23e9a27","_uuid":"ef4269de-ed75-44d5-bb9c-6f9a5aa52c38"},"source":["#### $\\bullet$ Is this algorithm the optimal one to produce this output? If not, can you suggest a better algorithm to perform the same task?"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e67e77c-00a2-4132-b8fd-87aaad8cf8e9","_uuid":"df118771-99a5-49a6-8500-226101d9f6fa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"6a3e5c47-2223-4f14-bdb7-f1d319653242","_uuid":"f1e62ea1-ae08-4ca1-a17d-8d0409c00b26"},"source":["### 3. __[AQ2] Considering the following problem, answer the questions:__"]},{"cell_type":"markdown","metadata":{"_cell_guid":"3741a918-831b-4fb7-ae2c-dfb2ff9ca658","_uuid":"0b3a317b-5d47-4eb6-92f2-a188cc9c925f"},"source":["#### Alex has a ribbon of length N. He wants to cut the ribbon in a way that fulfils the following __three__ conditions:\n","- Each piece of the cut should have an integer length\n","- He should at least cut the ribbon once\n","- The __multiplication__ of the length of all the pieces be the maximum possible"]},{"cell_type":"markdown","metadata":{"_cell_guid":"669ca1f5-c1de-4a6a-b9a8-a3f8998c23e9","_uuid":"fd572a08-79bf-4e04-9e55-deb7a1b43b7d"},"source":["#### 1. Implement a __recursive algorithm__ to help Alex find the maximum possible value after multiplying the length of the pieces. Explain your algorithm in detail."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b8f7171-953c-4079-b2e5-630a3a9b37d1","_uuid":"d4cb4c89-aa4d-4a62-ade2-4a7bd61fcf6e"},"outputs":[],"source":["def ribbon_cut_exp(N):\n","    if N <= 2:\n","        return 1\n","    l = [N]\n","    for i in range(1,N//2+1):\n","        l.append(max(i, ribbon_cut_exp(i)) * max(N-i, ribbon_cut_exp(N-i)))\n","    return max(l)\n","                            \n","ribbon_cut_exp(27)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a557f5e3-79e4-4f3a-afa0-5dc794ae6d9f","_uuid":"c099e861-abc2-4199-838a-4e91f28200a6"},"source":["#### 2. Show that the algorithm has exponential running time."]},{"cell_type":"markdown","metadata":{"_cell_guid":"81ed765c-866f-4fa9-8fa0-dd7691c81cd5","_uuid":"63806aaa-ac13-4336-8001-51fb4cc4da7b"},"source":["When the function is called with a certain parameter $N$ the func calls $N-1$ other instances of itself with parameters $\\{n | n \\in (1,N-1)\\}$. Each function has $O(n)$ complexity, since it finds the maximum in an array of length $n/2$.\n","\n","So the number of executions is\n","$$\n","    (N-2) + 2^1(N-3) + 2^2(N-4) + 2^3(N-5) + ... + 2^N 1 = O(2^N) \n","$$"]},{"cell_type":"markdown","metadata":{"_cell_guid":"dd5e218e-edaa-4a1a-8500-85e680d37ed6","_uuid":"c3d785b9-d1b6-4a64-a543-e8a457f904af"},"source":["#### 3. Now provide a polynomial solution, based on __dynamic programming__, and compute its running-time complexity."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13589aaa-73c2-4888-b8d3-f79d6d2fbbd8","_uuid":"976deeee-cc09-489c-84e0-27911c76ea91"},"outputs":[],"source":["def ribbon_cut_poly(N):\n","    if N <= 2:\n","        return 1\n","    cuts = [1,2]\n","    for x in range(3,N+1):\n","        l = [x]\n","        for i in range(1,x//2+1):\n","            l.append(max(i, cuts[i-1]) * max(x-i, cuts[x-i-1]))\n","        cuts.append(max(l))\n","    # print(cuts)\n","    return cuts[N-1]\n","    \n","ribbon_cut_poly(12)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"52da5a35-9f2f-48ea-adb4-8942f68df07b","_uuid":"d47253b3-1478-4087-a030-837cd63501e3"},"source":["At the $j^{th}$ iteration of the outer loop, it iterates $j/2$ times in the inner loop. The inner loop computes some $O(1)$ operations and then appends at the result at a list ($O(1)$). At the end a search for the maximum is performed on an array of length $j/2$, complexity of this last operation is $O(j/2)$.\n","At the end the total number of operations performed is:\n","$$\n","    1 + 2 + ... + (N-1) + N = \\frac{N (N-1)}{2} = O(N^2)\n","$$"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6bcee46e-6735-4fad-9fbe-bbcaac21e48c","_uuid":"1a7f2740-2be1-4c83-9817-5abdfd4b16fa"},"source":["#### 4. Evaluate the running time of your algorithm for the sizes (Ns) in the __range of [2, 25]__, plot the results, and interpret it (if you have implemented two algorithms, please include both in the plot and compare them)."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6eda1263-694e-465b-9f3d-bae0502c1830","_uuid":"9a8c348c-9316-400f-8d95-fcbf97a837cb"},"outputs":[],"source":["from timeit import timeit\n","\n","performance = {\n","    'time' : [],\n","    'type' : [],\n","    'N' : []\n","}\n","N_RANGE = 26\n","for i in range(2,N_RANGE):\n","    print(f\"{i}th iteration\")\n","    performance['time'].append(timeit(lambda: ribbon_cut_poly(i), number = 10000) * 10**3)\n","    performance['type'].append('poly')\n","    performance['N'].append(i)\n","    \n","    performance['N'].append(i)\n","    performance['time'].append(timeit(lambda: ribbon_cut_exp(i), number=1000) * 10**3)\n","    performance['type'].append('exp')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7a6a46e-7d36-4cac-957c-0e43aa24647a","_uuid":"962ff5a2-3b12-4524-86c9-74f4afc2ef0f"},"outputs":[],"source":["cut_performance = pd.DataFrame.from_dict(performance)\n","sns.lineplot(data=cut_performance,x='N', y='time', hue='type', palette='pastel')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e148608e-d398-42bb-bc9b-7afc3f591d80","_uuid":"c1619656-2af6-4a0c-893e-58e3ee4ad7f0"},"source":["#### 5. (Optional, mini bonus) Is the algorithm of question 3 __optimal__? If you belive it, can you prove it? If not, can you find a faster algorithm? In case you found a faster algorithm implement it and explain your algorithm in detail."]},{"cell_type":"markdown","metadata":{"_cell_guid":"566f41b8-a87d-4873-8d76-54329c8f44c9","_uuid":"319e78d7-4c23-4910-a6d8-dcc15ad42fa9"},"source":["The algorithm is not optimal, because the answer can be easily computed by a constant function with complexity $O(1)$\n","\n","$\n","f(x) = \n","\\begin{cases} \n","          x & 0 < x \\leq 2 \\\\\n","          3^{\\frac{x}{3}} & x \\mod{3} = 0 \\\\\n","          2^2 \\cdot 3^{\\frac{(x-4)}{3}} & x \\mod{3} = 1\\\\\n","          2 \\cdot 3^{\\frac{x-2}{3}} & x \\mod{3} = 2\n","       \\end{cases}\n","$"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15e84737-f811-46a4-86a7-dca20a8e263f","_uuid":"917fd8ed-4783-47de-a4f8-c522bf6ffc0e"},"outputs":[],"source":["def ribbon_cut_const(N):\n","    if N <= 3:\n","        return N\n","    if N % 3 == 0:\n","        return 3** (N // 3)\n","    if N % 3 == 1:\n","        return 4 * 3** ((N-4)//3)\n","    if N % 3 == 2:\n","        return 3**(N//3) * 2\n","    \n","ribbon_cut_const(26)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"531f4dde-0bcc-4e4b-8866-60551304e9c2","_uuid":"85255e3c-1396-45cf-88ad-569c08f3620a"},"outputs":[],"source":["for i in range(1,N_RANGE):\n","    performance['N'].append(i)\n","    performance['time'].append(timeit(lambda: ribbon_cut_const(i), number=1000) * 10**3)\n","    performance['type'].append('const')\n","    \n","cut_performance = pd.DataFrame.from_dict(performance)\n","sns.lineplot(data=cut_performance,x='N', y='time', hue='type', palette='pastel')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"d0d9de1bd73e5057d6899d8fb9583eaa7e585bedee5ed3c304303aa57f28dd3f"}}},"nbformat":4,"nbformat_minor":4}
