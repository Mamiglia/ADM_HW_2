{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174027f2-01af-4e80-a15c-fbc75f32dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85655cb1-614d-4667-86bf-028feb1c475c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/andrea/opt/anaconda3/lib/python3.9/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/andrea/opt/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cb26-a453-4ac6-8389-1c90db419de8",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## __Preprocessing__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcfeeb6-ffb9-4589-a3ba-8239913fe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, file:str):\n",
    "        self.file_name : str = file\n",
    "        self.types : dict = self.load_types()\n",
    "        self.df : pd.DataFrame = None\n",
    "        \n",
    "    def name(self):\n",
    "        return re.search(r'\\/([\\w\\d]*)\\.csv',self.file_name).group(1)\n",
    "    \n",
    "    def __types_file__(self):\n",
    "        return 'kaggle/working/'+ self.name() +'.npy'\n",
    "        \n",
    "    def save_types(self):\n",
    "        np.save(self.__types_file__(), self.types)\n",
    "        \n",
    "    def load_types(self):\n",
    "        if os.path.isfile(self.__types_file__()):\n",
    "            self.types = np.load(self.__types_file__(),allow_pickle='TRUE').item()\n",
    "            return self.types\n",
    "        return None\n",
    "    \n",
    "    def col(self,columns:list, index:bool=True,**pd_params)->pd.DataFrame:\n",
    "        \"\"\"Loads some columns of the dataframe out of the whole csv file\n",
    "        \n",
    "        :param columns: a list of the desired columns\n",
    "        :type columns: list\n",
    "        :param index: if True loads also the 'sid' column as the index\n",
    "        :type index: bool\n",
    "        :param **pd_params: any other params for pd.read_csv(...)\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        col_list = columns\n",
    "        if 'cts' in col_list:\n",
    "            pd_params['parse_dates'] = ['cts']\n",
    "        if index :\n",
    "            col_list.append('sid')\n",
    "        return pd.read_csv(self.file_name,\n",
    "                           usecols=col_list,\n",
    "                           dtype=self.types, \n",
    "                           index_col='sid' if index else None,\n",
    "                           delimiter='\\t', \n",
    "                           **pd_params)\n",
    "\n",
    "datasets = [\n",
    "    Dataset(file='../input/instagram-dataset/instagram_profiles.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_locations.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_posts.csv')\n",
    "]\n",
    "profiles, locations, posts = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f090725-1f85-459e-8fd8-6cff54c492f3",
   "metadata": {},
   "source": [
    "Columns and inferred types from descrption \n",
    "TODO DESCRIBE MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cddca29-5f8a-4e77-a170-29cb1f99b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.types = {\n",
    "#     'sid' : 'Int64',\n",
    "    'profile_id' : 'Int64',\n",
    "    'profile_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'firstname_lastname' : pd.StringDtype(storage='pyarrow'),\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'following' : 'Int64',\n",
    "    'followers' : 'Int64',\n",
    "    'n_posts' : 'Int64',\n",
    "    'url' : pd.StringDtype(storage='pyarrow'),\n",
    "#     'cts' : pd.DatetimeTZDtype(tz='UTC'), #obtained through parse_dates=['cts']\n",
    "    'is_business_account' : pd.BooleanDtype()\n",
    "}\n",
    "posts.types = {\n",
    "#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n",
    "    'sid_profile' : 'Int64',\n",
    "    'post_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'profile_id' : 'Int64',\n",
    "    'location_id' : 'Int64',\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'post_type' : pd.CategoricalDtype(categories=[1,2,3]),\n",
    "    'numbr_likes' : 'Int64',\n",
    "    'number_comments' : 'Int64'\n",
    "}\n",
    "locations.types = {\n",
    "#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n",
    "    'id' : 'Int64',\n",
    "    'name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'street' : pd.StringDtype(storage='pyarrow'),\n",
    "    'zip' : pd.StringDtype(storage='pyarrow'),\n",
    "    'city' : pd.StringDtype(storage='pyarrow'),\n",
    "    'region' : pd.StringDtype(storage='pyarrow'),\n",
    "    'cd' : pd.CategoricalDtype(),\n",
    "    'phone' : pd.StringDtype(storage='pyarrow'),\n",
    "    'aj_exact_city_match' : pd.BooleanDtype(),\n",
    "    'aj_exact_country_match' : pd.BooleanDtype(),\n",
    "    'blurb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_country_id' : pd.CategoricalDtype(),\n",
    "    'dir_country_name' : pd.CategoricalDtype(),\n",
    "    'lat' : pd.Float32Dtype(),\n",
    "    'lng' : pd.Float32Dtype(),\n",
    "    'primary_alias_on_fb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'website' : pd.StringDtype(storage='pyarrow'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0aab5f2-0944-4188-b533-a0031d3520a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(signed=True, unsigned=True, custom=[]):\n",
    "    '''Returns a pandas dataframe containing the boundaries of each integer dtype'''\n",
    "    # based on https://stackoverflow.com/a/57894540/9419492\n",
    "    pd_types = custom\n",
    "    if signed:\n",
    "        pd_types += [pd.Int8Dtype() ,pd.Int16Dtype() ,pd.Int32Dtype(), pd.Int64Dtype()]\n",
    "    if unsigned:\n",
    "        pd_types += [pd.UInt8Dtype() ,pd.UInt16Dtype(), pd.UInt32Dtype(), pd.UInt64Dtype()]\n",
    "    type_df = pd.DataFrame(data=pd_types, columns=['pd_type'])\n",
    "    type_df['np_type'] = type_df['pd_type'].apply(lambda t: t.numpy_dtype)\n",
    "    type_df['min_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).min)\n",
    "    type_df['max_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).max)\n",
    "    type_df['allow_negatives'] = type_df['min_value'] < 0\n",
    "    type_df['size'] = type_df['np_type'].apply(lambda row: row.itemsize)\n",
    "    type_df.sort_values(by=['size', 'allow_negatives'], inplace=True)\n",
    "    return type_df.reset_index(drop=True)\n",
    "def downcast_int(file_path, column:str, chunksize=10000, delimiter=',', signed=True, unsigned=True):\n",
    "    '''Assigns the smallest possible dtype to an integer column of a csv'''\n",
    "    types = get_types(signed, unsigned)\n",
    "    negatives = False\n",
    "    print(delimiter)\n",
    "    for chunk in pd.read_csv(file_path, \n",
    "                             usecols=[column],\n",
    "                             delimiter=delimiter,\n",
    "                             chunksize=chunksize):\n",
    "        M = chunk[column].max()\n",
    "        m = chunk[column].min()\n",
    "        if not signed and not negatives and m < 0 :\n",
    "            types = types[types['allow_negatives']] # removes unsigned rows\n",
    "            negatives = True\n",
    "        if m < types['min_value'].iloc[0]:\n",
    "            types = types[types['min_value'] < m]\n",
    "        if M > types['max_value'].iloc[0]:\n",
    "            types = types[types['max_value'] > M]\n",
    "        if len(types) == 1:\n",
    "            print('early stop')\n",
    "            break\n",
    "    return types['pd_type'].iloc[0]\n",
    "\n",
    "def optimize_cols(file, int_cols, delimiter=',', signed=True, unsigned=True):\n",
    "    out = dict()\n",
    "    for col in int_cols:\n",
    "        out[col] = downcast_int(file, col, delimiter=delimiter, signed=signed, unsigned=unsigned)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34857117-7869-4132-8ed6-b148c95a6e5f",
   "metadata": {},
   "source": [
    "Optimize types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9243db11-d621-4790-a22f-163763165d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instagram_profiles  mean optimized memory usage per entry:  150 B vs  542 B  : 27.71%\n",
      "instagram_locations mean optimized memory usage per entry:  272 B vs 1117 B  : 24.34%\n",
      "instagram_posts     mean optimized memory usage per entry:  277 B vs  752 B  : 36.89%\n"
     ]
    }
   ],
   "source": [
    "for ds in datasets:\n",
    "    if not ds.load_types():\n",
    "        int_cols = [k for k,v in ds.types.items() if v == 'Int64']\n",
    "        print(int_cols)\n",
    "        ds.types.update(optimize_cols(ds.file_name, int_cols, delimiter='\\t'))\n",
    "        print(f'Optimized {len(int_cols)} types for {ds.name()}')\n",
    "    ds.save_types()\n",
    "\n",
    "for ds in datasets:\n",
    "    ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'], nrows=SAMPLE_SIZE)\n",
    "    avg_mem_unoptimized = pd.read_csv(ds.file_name, index_col='sid', delimiter='\\t', nrows=SAMPLE_SIZE).memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    avg_mem_optimized = ds.df.memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    print(f'{ds.name().ljust(19)} mean optimized memory usage per entry:  {round(avg_mem_optimized):3} B vs {round(avg_mem_unoptimized):4} B  : {round(avg_mem_optimized/avg_mem_unoptimized*100,2):5}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17f2b6-63f3-45f8-9434-6e45b4af5ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815e13f5-237e-4a6b-89a2-923dd1b41b3f",
   "metadata": {},
   "source": [
    "#### Profiles \n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| profile_id | Instagrams ID |\n",
    "| profile_name | profile name |\n",
    "| firstname_lastname | firstname lastname |\n",
    "| description | May contain '\\n' |\n",
    "| following | Number of following profile at the moment it was visited |\n",
    "| followers | Number of followers at the moment it was visited |\n",
    "| n_posts | Number of posts at the moment it was visited |\n",
    "| url | Url in profile description |\n",
    "| cts | Timestamp when the profile was visited |\n",
    "| is_business_account | Boolean flag if that profile was makred by the owner as business account |\n",
    "\n",
    "#### Locations\n",
    "\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| ID | Instagrams ID |\n",
    "| Name | Locations Name |\n",
    "| Street | Street Address, may contain '\\n' |\n",
    "| ZIP | Zip code |\n",
    "| City | City Name |\n",
    "| Region | Region |\n",
    "| CD | Country Code |\n",
    "| Phone | The phone in format as on the Instragram |\n",
    "| aj_exact_city_match | The Instagrams Internal key |\n",
    "| aj_exact_country_match | The Instagrams Internal key |\n",
    "| blurb | Description of the place, may contain '\\n' |\n",
    "| dir_city_id | The Instagrams internal City ID |\n",
    "| dir_city_name | city Name |\n",
    "| dir_city_slug | City tag (sortof) |\n",
    "| dir_country_id | Country ID |\n",
    "| dir_country_name | country |\n",
    "| lat | Latitude |\n",
    "| lng | Longtitude |\n",
    "| primary_alias_on_fb | Bool Flag |\n",
    "| slug | ??? |\n",
    "| website | The URL to web site, may contain more then 1 URL, may contain '\\n' |\n",
    "| cts | Timestamp when the location was visited |\n",
    "\n",
    "#### Posts\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| sid_profile | Sequence ID of the profile from *Profiles* table |\n",
    "| post_id | Instagrams ID |\n",
    "| profile_id | Instagrams ID may be null |\n",
    "| location_id | Instagrams ID |\n",
    "| cts | Timestamp when the Post was created |\n",
    "| post_type | 1 - Photo, 2 - Video, 3 - multy |\n",
    "| description | May contain '\\n' |\n",
    "| number_likes | Number of Likes at the moment it was visited |\n",
    "| number_comments | Number of comments at the moment it was visited |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb1873-f093-423d-a415-056ba801458c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### __1. [RQ1] After collecting information, the Data Scientists have to know what dataset they are dealing with, so let's start with an Exploratory Data Analysis (EDA). What can you say about our datasets? Please summarise its main characteristics with visual and tabular methods.__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3fb472-897d-428e-8f1f-3e21c7e078e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59be3cdf-712c-41be-b8a2-bd3324a97d3e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### __2. [RQ2] Let's explore the dataset by finding simple insights regarding the profile and posts.__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc319b9-ad99-4587-8975-2c494dfeb27d",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Plot the number of posts for each profile in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd0708-144a-40c0-afe7-a9cc51199c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51fac33e-e7a7-4836-8234-f0fbb195fb5e",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What posts have the highest number of \"likes\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e049f-b782-4077-ae3d-573dec8572b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e73fb57-3526-4c50-a051-962d2c62d4a7",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What posts have the most and the least number of comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15b128-cd69-4bc1-a0c1-515448ff3e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e57f6d1-0ccf-4a35-86a9-225085daa0fd",
   "metadata": {},
   "source": [
    "#### $\\bullet$ How many posts include tagged locations, and how many do not? Show it using an appropriate chart and comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364669f5-7c53-4170-8a64-9b105ae7e205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439b07e1-f419-4800-bcb7-d90a58044ab8",
   "metadata": {},
   "source": [
    "#### $\\bullet$ How many posts include only photos? How many also have videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647659c-3833-4e5e-b981-de2284e0f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1043ffc2-3988-4644-b72a-019cceb6b32a",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What's the percentage of business accounts vs non- business? What can you interpret regarding that percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fde655-0045-4ea3-a603-31221123c50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "835228dd-db37-4a40-b200-6393143cc866",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 3. __[RQ3] Now it's important to understand the most common times in which users publish their posts__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e76769-bc80-4b21-b330-92d1e6a99882",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What is the most common time in which users publish their posts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f987c8-1539-4cd6-a4e0-e2a2dc4b79da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aff1f4a-f5c6-4867-9e6a-d015f1829c21",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Create a function that receives a time intervals list as a parameter and returns a plot with the number of posts for each given interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbe030-6129-4c52-9132-b8d917831251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b471ae-90aa-48e4-9276-0c10982ab18a",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Use the function that you created in the previous literal to plot the number of posts between the following time intervals:\n",
    "\n",
    "| Initial time | Final time |\n",
    "|---|---|\n",
    "| 06:00:00 | 10:59:59 |\n",
    "| 11:00:00 | 13:59:59 |\n",
    "| 14:00:00 | 16:59:59 |\n",
    "| 17:00:00 | 19:59:59 |\n",
    "| 20:00:00 | 23:59:59 |\n",
    "| 00:00:00 | 02:59:59 |\n",
    "| 03:00:00 | 05:59:59 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495a29e-b9b8-4272-a372-4a319f7a0b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f655c1e-46e4-4634-9654-59cc62df9949",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 4. __[RQ4] In most cases, we will not have a consistent dataset, and the one we are dealing with is not an exception (ex. in the given datasets, you may not find the information of the profiles for some of the posts). So let’s enhance our analysis.__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ca010-450c-485b-8b86-c460739488ba",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Write a function that, given a profile_id, will be able to return the posts that belong to the given profile_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86400c-52ad-486c-86ec-ac97c7a8d76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c72489-20a3-4e1e-8321-5a1987aeaefd",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Write another function that, given an input n (an integer), will return the posts that belong to the n top posted profiles (top n profiles that have posted the highest number of posts) that their data is available in the profile.csv using the previously written function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718fb1c-3aca-4d5a-8957-2e72f647a511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfea10f2-ed15-433c-8369-f4988543ee1e",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What is the average number of \"likes\" and comments of the top 10 profiles with the highest number of posts which their information is available in profile.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823b3f9-1994-4d55-b90a-6a3dced791d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "275c492d-810e-48bc-ba03-08432ea5b8e8",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Plot the number of posts that these top 10 profiles have sent on Instagram in the given interval in question RQ3. Interpret the resulting chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e8f22-9e01-488b-8623-ad35008f5318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fbbd88-6c95-4da3-a4f9-8d0394e61a82",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 5. __[RQ5] The most influential users are the ones with the highest number of “followers\", you can now look more into their activity.__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75acbaac-e5e9-4e59-a763-1c8fca10dc89",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Plot the top 10 most popular users in terms of followers and their number of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e34a2-a4d1-47e5-b5a2-502dbdb617bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b14401-3f03-4db9-be1f-a89c4f450f86",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Who is the most influential user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda4655-f463-41d9-9a24-0786b5b21c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93562344-5131-4534-afd6-fa76261e3009",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Have they posted anything with tagged locations? Extract the most frequent areas on their posts and plot the number of times each city has been visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43514ed-f5a3-4918-974b-1f00600db1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3726e9f6-7207-4ae6-b721-1350b73c8698",
   "metadata": {},
   "source": [
    "#### $\\bullet$ How many pictures-only posts have they published? How many reels? (only videos) and how many with both contents? Provide the number as percentages and interpret those figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606009c-c405-4be8-9e29-496a4cab462b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25181378-3250-4caa-b617-b8d485209fce",
   "metadata": {},
   "source": [
    "#### $\\bullet$ How many \"likes\" and comments did posts with only pictures receive? How about videos and mixed posts? Try to provide the average numbers and confront them with their followers amount, explaining what you can say from that comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e0c82-70f7-4b74-bc39-4f0e05fa8409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be90c63-7465-4d25-a14e-fc5c21837976",
   "metadata": {},
   "source": [
    "### 6. __[RQ6] It's time to get information from the user posting effectiveness.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b81fc-c101-4826-a55c-bc7416ee61cd",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What is the average time (days and minutes) a user lets pass before publishing another post? Plot the top 3 users that publish posts more frequently (calculate the average time that passes between posts), including their amount of followers and following. Provide insights from that chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc03700-33ad-48c0-8e21-380b93324e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d0f199-9325-49dc-a9b3-4965ff906636",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Using the function you previously coded, plot the time intervals with the highest average number of “likes” and the ones with the highest average number of comments on posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6be9c-83cf-475d-b2fe-f286e8f7d2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba74355-9452-4263-bd24-3713fbfdcf4f",
   "metadata": {},
   "source": [
    "#### 7. __[RQ7] Of course, calculating probabilities is a job that any Data Scientist must know. So let's compute some engaging figures__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c60d2-ed81-41e5-a684-c7b90c4e9263",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What's the probability that a post receives more than 20% \"likes\" of the number of followers a user has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2051c-0b62-4840-a801-62270c9a3e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c775ce-e42b-4095-ae3f-80981a77e02d",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Do users usually return to locations? Extract the probability that a user returns to a site after having posted it in the past. Does that probability make sense to you? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4412f50-ccc0-4c17-8687-feaae3965629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fb2612d-c19c-4a26-ad22-192568f7a542",
   "metadata": {},
   "source": [
    "### 8. __[RQ8] Every decision you take in a data-based environment should be reinforced with charts, statistical tests and analysis methods to check whether a hypothesis is correct or not.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497d3f0-bccb-445f-825f-d3772975e512",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Does more “likes” also mean more comments? Plot a scatter plot of “likes” vs comments for posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a5a77-d027-407d-8505-31baacc7ba84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4611bf8b-a613-4c18-8932-b823eb9b452b",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Can you find any significant relationship between the time a user publishes a post and the number of comments and “likes”? Use an appropriate statistical test or technique and support your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1913b27-e803-47cb-abd5-5670568bf88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a30504-8871-43b4-9a6e-9e404c8066b2",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What’s the distribution of followers? Plot the empirical distribution of followers amongst all users and extract the mean, mode, and quantiles. Interpret those figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5a327-3e48-41c3-8c32-ad5df4a3be2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f06eb143-006a-4035-b5d9-ff07fd404aaa",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What are histograms, bar plots, scatterplots and pie charts used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2a6ba-cdd7-42ce-bd17-0ef910d4aad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4c9cf5-d311-4cbf-8e3a-f402b1f28ca1",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What insights can you extract from a Box Plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e01df0-c8ab-446f-92ad-f5483defbaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e603983-6ba7-408b-8181-271b75632af4",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## __Bonus points__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef1940-a2e4-4c7e-9f38-1bb8bf49a249",
   "metadata": {},
   "source": [
    "#### Up to this point, you probably have worked with one or two files simultaneously. Nevertheless, for the literals a. and b. of this section, you must work with the three datasets at the same time. Note that performing some of these operations might be too complex for your pc specs. For this reason, we suggest you make use of AWS (yeah! only a suggestion). In case you need it, in the following links you can find the same three files already mounted into AWS for you to work with them easily (instagram_posts, instagram_profiles, instagram_locations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5ab43-7837-49d2-b102-d98241798710",
   "metadata": {},
   "source": [
    "#### a. Sort the users in terms of number of followers and divide them into two groups: for the first group, take only the top 10% regarding \"followers\", and for the second one, take the rest. Now compare the mean of time intervals between posts for the two categories. Do you notice something relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33087d1-9196-4499-acdf-67af2911bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06202153-5924-41a0-8412-ca0438088b0e",
   "metadata": {},
   "source": [
    "#### b. Assume users publish their posts the same day pictures or videos are taken: Are there users that have visited the same location on the same day? How about the same week? Extract the results and explain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876ab00-c3aa-4395-87cf-4f8cdc77c0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56937824-e49d-4153-a367-a313ebd2b93c",
   "metadata": {},
   "source": [
    "#### c. Implement a text data analysis (also known as text mining) of the field \"description\" from instagram_posts.csv for descriptions written in English. Use appropriate visualizations and statistics to highlight the words (and probably the topics) provided for the users in that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee8287-8e4a-46ae-9242-6141c76b5578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955591ca-0171-4198-ad88-f76e29a3a9c6",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## __Command Line Question__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd70440-acac-403b-a5bd-c964d459904d",
   "metadata": {},
   "source": [
    "#### Using the command line is a feature that Data Scientists must master. It is relevant since the operations there require less memory to use in comparison to other interfaces. It also does not use as much CPU processing time as other interfaces. In addition, it can be faster and more efficient and handle repetitive tasks quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abb383-f52a-4468-af6b-dcea52868f9d",
   "metadata": {},
   "source": [
    "#### In this question, you should use command line tools such as grep and possibly other commands to answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f6dca-a66a-4b7c-8f37-411d92020321",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Using the instagram_posts.csv, retrieve the first ten posts with descriptions longer than 100 characters and output the profiles that posted them. (Please keep in mind that the profile associated with some of those posts may not be found in the profiles. You can simply output User was not found! for those posts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40b987-1704-4228-bc34-a5e01139f796",
   "metadata": {},
   "source": [
    "#### Note: You may work on this question in any environment (AWS, your PC command line, Jupyter notebook, etc.), but the final script must be placed in CommandLine.sh, which must be executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a75c19-50eb-4a2a-9347-d52662a57938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586c27e1-9654-4a73-a8b4-84a72a008f05",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## __Algorithmic Question__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d605d0-830b-4d49-928a-b3dafc449d62",
   "metadata": {},
   "source": [
    "### 1. __[AQ1] Given the following pseudocode, answer the questions:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bcf32f-14b7-4f65-a1d1-99507d2828a9",
   "metadata": {},
   "source": [
    "Input:\n",
    "       N : an integer\n",
    "       List : array of characters of leng\n",
    "   function f1(sequence, end):\n",
    "       For i=0 To end:\n",
    "           OUTPUT sequence[i]\n",
    "       EndFor\n",
    "Output \"\\n\"\n",
    "   function f2(sequence, start, end):\n",
    "       If start = end:\n",
    "           f1(sequence, end)\n",
    "       Else\n",
    "           For i=start To end:\n",
    "               temp <-- sequence[start]\n",
    "               sequence[start] <-- sequen\n",
    "               sequence[i] <-- temp\n",
    "               f2(sequence, start+1, end)\n",
    "               temp <-- sequence[start]\n",
    "               sequence[start] <-- sequen\n",
    "               sequence[i] <-- temp\n",
    "   f2(List, 0, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325d434-653b-4cf0-9eb2-e1633c9b4202",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What is the output of this algorithm? Describe the mechanism of the algorithm in detail . We do not want to know only its final result. (Describe one example on your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01c043-c705-4468-9bff-b8f75502251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0020511-5c43-4bbc-aa4c-11351f6d0030",
   "metadata": {},
   "source": [
    "#### $\\bullet$ What is asymptotically (i.e., we are asking for big-O complexity) the algorithm's running time as a function of N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ca184-ff82-4df8-82eb-055dfb5f319d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "976f3dee-e44b-4845-bb01-05670814dabd",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Is this algorithm the optimal one to produce this output? If not, can you suggest a better algorithm to perform the same task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591713c-7119-41e9-a6aa-6c36c7df6ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e876e76f-0423-424b-ae2d-39e67ea7aa98",
   "metadata": {},
   "source": [
    "### 3. __[AQ2] Considering the following problem, answer the questions:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f112cb-9fc8-459e-8fb0-199f64443f18",
   "metadata": {},
   "source": [
    "#### Alex has a ribbon of length N. He wants to cut the ribbon in a way that fulfils the following __three__ conditions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b7932-b459-4ad4-baab-cc7d6c771e2c",
   "metadata": {},
   "source": [
    "#### $\\bullet$ Each piece of the cut should have an integer length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02248ee8-b526-4230-a5de-9888d96fc262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f09a40-456f-4614-8edf-1e7ad192bf1d",
   "metadata": {},
   "source": [
    "#### $\\bullet$ He should at least cut the ribbon once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9d747-5e9b-4931-ad5f-fcd5b1c2b5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37bad988-e744-4238-b548-a73c89325ecc",
   "metadata": {},
   "source": [
    "#### $\\bullet$ The __multiplication__ of the length of all the pieces be the maximum possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb8f21-4d37-4378-b572-55c492be1b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a445f338-48ec-4664-8790-d739e88488ba",
   "metadata": {},
   "source": [
    "#### 1. Implement a __recursive algorithm__ to help Alex find the maximum possible value after multiplying the length of the pieces. Explain your algorithm in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabcb50-1a72-4690-93d5-824a075c036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b356a5-506a-4a85-9d2e-ddd9d1d9a2c3",
   "metadata": {},
   "source": [
    "#### 2. Show that the algorithm has exponential running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71f85d-1adb-441d-b207-29f866f8d526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99973677-ee92-4005-9bfd-b75ce2d3c693",
   "metadata": {},
   "source": [
    "#### 3. Now provide a polynomial solution, based on __dynamic programming__, and compute its running-time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619ed74-8508-4c78-a826-6f2c436045b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44444860-ff9a-4388-8de9-144eade5a150",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the running time of your algorithm for the sizes (Ns) in the __range of [2, 25]__, plot the results, and interpret it (if you have implemented two algorithms, please include both in the plot and compare them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e1ccc-8375-424a-982b-8b022e392bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea55e4e0-ef1a-402c-89a8-e2e41773fdb5",
   "metadata": {},
   "source": [
    "#### 5. (Optional, mini bonus) Is the algorithm of question 3 __optimal__? If you belive it, can you prove it? If not, can you find a faster algorithm? In case you found a faster algorithm implement it and explain your algorithm in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38a202-0f43-413e-a730-972fa00e02be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
