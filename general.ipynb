{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174027f2-01af-4e80-a15c-fbc75f32dba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cb26-a453-4ac6-8389-1c90db419de8",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfeeb6-ffb9-4589-a3ba-8239913fe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, file:str):\n",
    "        self.file_name : str = file\n",
    "        self.types : dict = self.load_types()\n",
    "        self.df : pd.DataFrame = None\n",
    "        \n",
    "    def name(self):\n",
    "        return re.search(r'\\/([\\w\\d]*)\\.csv',self.file_name).group(1)\n",
    "    \n",
    "    def types_file(self):\n",
    "        return '/kaggle/working/'+ self.name() +'.npy'\n",
    "        \n",
    "    def save_types(self):\n",
    "        np.save(self.types_file(), self.types)\n",
    "        \n",
    "    def load_types(self):\n",
    "        if os.path.isfile(self.types_file()):\n",
    "            self.types = np.load(self.types_file(),allow_pickle='TRUE').item()\n",
    "            return self.types\n",
    "        return None\n",
    "\n",
    "datasets = [\n",
    "    Dataset(file='../input/instagram-dataset/instagram_profiles.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_locations.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_posts.csv')\n",
    "]\n",
    "profiles, locations, posts = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f090725-1f85-459e-8fd8-6cff54c492f3",
   "metadata": {},
   "source": [
    "Columns and inferred types from descrption \n",
    "TODO DESCRIBE MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddca29-5f8a-4e77-a170-29cb1f99b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.types = {\n",
    "#     'sid' : int,\n",
    "    'profile_id' : int,\n",
    "    'profile_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'firstname_lastname' : pd.StringDtype(storage='pyarrow'),\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'following' : int,\n",
    "    'followers' : int,\n",
    "    'n_posts' : int,\n",
    "    'url' : pd.StringDtype(storage='pyarrow'),\n",
    "#     'cts' : pd.DatetimeTZDtype(tz='UTC'), #obtained through parse_dates=['cts']\n",
    "    'is_business_account' : pd.BooleanDtype()\n",
    "}\n",
    "posts.types = {\n",
    "#     'sid' : int, # gives an error, maybe because it's the index?\n",
    "    'sid_profile' : int,\n",
    "    'post_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'profile_id' : int,\n",
    "    'location_id' : int,\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'post_type' : pd.CategoricalDtype(categories=[1,2,3]),\n",
    "    'numbr_likes' : int,\n",
    "    'number_comments' : int\n",
    "}\n",
    "locations.types = {\n",
    "#     'sid' : int, # gives an error, maybe because it's the index?\n",
    "    'id' : int,\n",
    "    'name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'street' : pd.StringDtype(storage='pyarrow'),\n",
    "    'zip' : pd.StringDtype(storage='pyarrow'),\n",
    "    'city' : pd.StringDtype(storage='pyarrow'),\n",
    "    'region' : pd.StringDtype(storage='pyarrow'),\n",
    "    'cd' : pd.CategoricalDtype(),\n",
    "    'phone' : pd.StringDtype(storage='pyarrow'),\n",
    "    'aj_exact_city_match' : pd.BooleanDtype(),\n",
    "    'aj_exact_country_match' : pd.BooleanDtype(),\n",
    "    'blurb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_country_id' : pd.CategoricalDtype(),\n",
    "    'dir_country_name' : pd.CategoricalDtype(),\n",
    "    'lat' : pd.Float32Dtype(),\n",
    "    'lng' : pd.Float32Dtype(),\n",
    "    'primary_alias_on_fb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'website' : pd.StringDtype(storage='pyarrow'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aab5f2-0944-4188-b533-a0031d3520a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(signed=True, unsigned=True, custom=[]):\n",
    "    '''Returns a pandas dataframe containing the boundaries of each integer dtype'''\n",
    "    # based on https://stackoverflow.com/a/57894540/9419492\n",
    "    pd_types = custom\n",
    "    if signed:\n",
    "        pd_types += [pd.Int8Dtype() ,pd.Int16Dtype() ,pd.Int32Dtype(), pd.Int64Dtype()]\n",
    "    if unsigned:\n",
    "        pd_types += [pd.UInt8Dtype() ,pd.UInt16Dtype(), pd.UInt32Dtype(), pd.UInt64Dtype()]\n",
    "    type_df = pd.DataFrame(data=pd_types, columns=['pd_type'])\n",
    "    type_df['np_type'] = type_df['pd_type'].apply(lambda t: t.numpy_dtype)\n",
    "    type_df['min_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).min)\n",
    "    type_df['max_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).max)\n",
    "    type_df['allow_negatives'] = type_df['min_value'] < 0\n",
    "    type_df['size'] = type_df['np_type'].apply(lambda row: row.itemsize)\n",
    "    type_df.sort_values(by=['size', 'allow_negatives'], inplace=True)\n",
    "    return type_df.reset_index(drop=True)\n",
    "    \n",
    "get_types()\n",
    "\n",
    "def downcast_int(file_path, column:str, chunksize=10000, delimiter=',', signed=True, unsigned=True):\n",
    "    '''Assigns the smallest possible dtype to an integer column of a csv'''\n",
    "    types = get_types(signed, unsigned)\n",
    "    negatives = False\n",
    "    for chunk in pd.read_csv(file_path, usecols=[column],delimiter=delimiter,skiprows=lambda x:x%100==0,chunksize=chunksize):\n",
    "        M = chunk[column].max()\n",
    "        m = chunk[column].min()\n",
    "        if not signed and not negatives and m < 0 :\n",
    "            types = types[types['allow_negatives']] # removes unsigned rows\n",
    "            negatives = True\n",
    "        if m < types['min_value'].iloc[0]:\n",
    "            types = types[types['min_value'] < m]\n",
    "        if M > types['max_value'].iloc[0]:\n",
    "            types = types[types['max_value'] > M]\n",
    "        if len(types) == 1:\n",
    "            print('early stop')\n",
    "            break\n",
    "    return types['pd_type'].iloc[0]\n",
    "\n",
    "def optimize_cols(file, int_cols, delimiter=',', signed=True, unsigned=True):\n",
    "    out = dict()\n",
    "    for col in int_cols:\n",
    "        out[col] = downcast_int(file, col, delimiter=delimiter, signed=signed, unsigned=unsigned)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34857117-7869-4132-8ed6-b148c95a6e5f",
   "metadata": {},
   "source": [
    "Optimize types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243db11-d621-4790-a22f-163763165d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    if not ds.load_types():\n",
    "        int_cols = [k for k,v in ds.types.items() if v is int]\n",
    "        print(int_cols)\n",
    "        ds.types.update(optimize_cols(ds.file_name, int_cols, delimiter='\\t'))\n",
    "        print(f'Optimized {len(int_cols)} types for {ds.name()}')\n",
    "#     ds.types.update({k:pd.StringDtype(storage='pyarrow') for k,v in ds.types.items() if v==pd.StringDtype(storage='pyarrow')})\n",
    "    ds.save_types()\n",
    "#     print(ds.types)\n",
    "\n",
    "for ds in datasets:\n",
    "    ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'], nrows=SAMPLE_SIZE)\n",
    "    avg_mem_unoptimized = pd.read_csv(ds.file_name, index_col='sid', delimiter='\\t', nrows=SAMPLE_SIZE).memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    avg_mem_optimized = ds.df.memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    print(f'{ds.name().ljust(19)} mean optimized memory usage per entry:  {round(avg_mem_optimized):3} B vs {round(avg_mem_unoptimized):4} B  : {round(avg_mem_optimized/avg_mem_unoptimized*100,2):5}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17f2b6-63f3-45f8-9434-6e45b4af5ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815e13f5-237e-4a6b-89a2-923dd1b41b3f",
   "metadata": {},
   "source": [
    "## RQ1 - EDA\n",
    "Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be3cdf-712c-41be-b8a2-bd3324a97d3e",
   "metadata": {},
   "source": [
    "## RQ2\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835228dd-db37-4a40-b200-6393143cc866",
   "metadata": {},
   "source": [
    "## RQ3\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f655c1e-46e4-4634-9654-59cc62df9949",
   "metadata": {},
   "source": [
    "## RQ4\n",
    "Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbbd88-6c95-4da3-a4f9-8d0394e61a82",
   "metadata": {},
   "source": [
    "## RQ5\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be90c63-7465-4d25-a14e-fc5c21837976",
   "metadata": {},
   "source": [
    "## RQ6\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba74355-9452-4263-bd24-3713fbfdcf4f",
   "metadata": {},
   "source": [
    "## RQ7\n",
    "Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2612d-c19c-4a26-ad22-192568f7a542",
   "metadata": {},
   "source": [
    "## RQ8\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4915e-cd96-4953-924c-5635c16c5483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
