{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174027f2-01af-4e80-a15c-fbc75f32dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85655cb1-614d-4667-86bf-028feb1c475c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /home/mamiglia/.local/lib/python3.10/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/mamiglia/.local/lib/python3.10/site-packages (from pyarrow) (1.23.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cb26-a453-4ac6-8389-1c90db419de8",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcfeeb6-ffb9-4589-a3ba-8239913fe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, file:str):\n",
    "        self.file_name : str = file\n",
    "        self.types : dict = self.load_types()\n",
    "        self.df : pd.DataFrame = None\n",
    "        \n",
    "    def name(self):\n",
    "        return re.search(r'\\/([\\w\\d]*)\\.csv',self.file_name).group(1)\n",
    "    \n",
    "    def __types_file__(self):\n",
    "        return 'kaggle/working/'+ self.name() +'.npy'\n",
    "        \n",
    "    def save_types(self):\n",
    "        np.save(self.__types_file__(), self.types)\n",
    "        \n",
    "    def load_types(self):\n",
    "        if os.path.isfile(self.__types_file__()):\n",
    "            self.types = np.load(self.__types_file__(),allow_pickle='TRUE').item()\n",
    "            return self.types\n",
    "        return None\n",
    "    \n",
    "    def col(self,columns:list, index:bool=True,**pd_params)->pd.DataFrame:\n",
    "        \"\"\"Loads some columns of the dataframe out of the whole csv file\n",
    "        \n",
    "        :param columns: a list of the desired columns\n",
    "        :type columns: list\n",
    "        :param index: if True loads also the 'sid' column as the index\n",
    "        :type index: bool\n",
    "        :param **pd_params: any other params for pd.read_csv(...)\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        col_list = columns\n",
    "        if 'cts' in col_list:\n",
    "            pd_params['parse_dates'] = ['cts']\n",
    "        if index :\n",
    "            col_list.append('sid')\n",
    "        return pd.read_csv(self.file_name,\n",
    "                           usecols=col_list,\n",
    "                           dtype=self.types, \n",
    "                           index_col='sid' if index else None,\n",
    "                           delimiter='\\t', \n",
    "                           **pd_params)\n",
    "\n",
    "datasets = [\n",
    "    Dataset(file='../input/instagram-dataset/instagram_profiles.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_locations.csv'), \n",
    "    Dataset(file='../input/instagram-dataset/instagram_posts.csv')\n",
    "]\n",
    "profiles, locations, posts = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f090725-1f85-459e-8fd8-6cff54c492f3",
   "metadata": {},
   "source": [
    "Columns and inferred types from descrption \n",
    "TODO DESCRIBE MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cddca29-5f8a-4e77-a170-29cb1f99b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.types = {\n",
    "#     'sid' : 'Int64',\n",
    "    'profile_id' : 'Int64',\n",
    "    'profile_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'firstname_lastname' : pd.StringDtype(storage='pyarrow'),\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'following' : 'Int64',\n",
    "    'followers' : 'Int64',\n",
    "    'n_posts' : 'Int64',\n",
    "    'url' : pd.StringDtype(storage='pyarrow'),\n",
    "#     'cts' : pd.DatetimeTZDtype(tz='UTC'), #obtained through parse_dates=['cts']\n",
    "    'is_business_account' : pd.BooleanDtype()\n",
    "}\n",
    "posts.types = {\n",
    "#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n",
    "    'sid_profile' : 'Int64',\n",
    "    'post_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'profile_id' : 'Int64',\n",
    "    'location_id' : 'Int64',\n",
    "    'description' : pd.StringDtype(storage='pyarrow'),\n",
    "    'post_type' : pd.CategoricalDtype(categories=[1,2,3]),\n",
    "    'numbr_likes' : 'Int64',\n",
    "    'number_comments' : 'Int64'\n",
    "}\n",
    "locations.types = {\n",
    "#     'sid' : 'Int64', # gives an error, maybe because it's the index?\n",
    "    'id' : 'Int64',\n",
    "    'name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'street' : pd.StringDtype(storage='pyarrow'),\n",
    "    'zip' : pd.StringDtype(storage='pyarrow'),\n",
    "    'city' : pd.StringDtype(storage='pyarrow'),\n",
    "    'region' : pd.StringDtype(storage='pyarrow'),\n",
    "    'cd' : pd.CategoricalDtype(),\n",
    "    'phone' : pd.StringDtype(storage='pyarrow'),\n",
    "    'aj_exact_city_match' : pd.BooleanDtype(),\n",
    "    'aj_exact_country_match' : pd.BooleanDtype(),\n",
    "    'blurb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_id' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_name' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_city_slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'dir_country_id' : pd.CategoricalDtype(),\n",
    "    'dir_country_name' : pd.CategoricalDtype(),\n",
    "    'lat' : pd.Float32Dtype(),\n",
    "    'lng' : pd.Float32Dtype(),\n",
    "    'primary_alias_on_fb' : pd.StringDtype(storage='pyarrow'),\n",
    "    'slug' : pd.StringDtype(storage='pyarrow'),\n",
    "    'website' : pd.StringDtype(storage='pyarrow'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0aab5f2-0944-4188-b533-a0031d3520a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(signed=True, unsigned=True, custom=[]):\n",
    "    '''Returns a pandas dataframe containing the boundaries of each integer dtype'''\n",
    "    # based on https://stackoverflow.com/a/57894540/9419492\n",
    "    pd_types = custom\n",
    "    if signed:\n",
    "        pd_types += [pd.Int8Dtype() ,pd.Int16Dtype() ,pd.Int32Dtype(), pd.Int64Dtype()]\n",
    "    if unsigned:\n",
    "        pd_types += [pd.UInt8Dtype() ,pd.UInt16Dtype(), pd.UInt32Dtype(), pd.UInt64Dtype()]\n",
    "    type_df = pd.DataFrame(data=pd_types, columns=['pd_type'])\n",
    "    type_df['np_type'] = type_df['pd_type'].apply(lambda t: t.numpy_dtype)\n",
    "    type_df['min_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).min)\n",
    "    type_df['max_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).max)\n",
    "    type_df['allow_negatives'] = type_df['min_value'] < 0\n",
    "    type_df['size'] = type_df['np_type'].apply(lambda row: row.itemsize)\n",
    "    type_df.sort_values(by=['size', 'allow_negatives'], inplace=True)\n",
    "    return type_df.reset_index(drop=True)\n",
    "def downcast_int(file_path, column:str, chunksize=10000, delimiter=',', signed=True, unsigned=True):\n",
    "    '''Assigns the smallest possible dtype to an integer column of a csv'''\n",
    "    types = get_types(signed, unsigned)\n",
    "    negatives = False\n",
    "    print(delimiter)\n",
    "    for chunk in pd.read_csv(file_path, \n",
    "                             usecols=[column],\n",
    "                             delimiter=delimiter,\n",
    "                             chunksize=chunksize):\n",
    "        M = chunk[column].max()\n",
    "        m = chunk[column].min()\n",
    "        if not signed and not negatives and m < 0 :\n",
    "            types = types[types['allow_negatives']] # removes unsigned rows\n",
    "            negatives = True\n",
    "        if m < types['min_value'].iloc[0]:\n",
    "            types = types[types['min_value'] < m]\n",
    "        if M > types['max_value'].iloc[0]:\n",
    "            types = types[types['max_value'] > M]\n",
    "        if len(types) == 1:\n",
    "            print('early stop')\n",
    "            break\n",
    "    return types['pd_type'].iloc[0]\n",
    "\n",
    "def optimize_cols(file, int_cols, delimiter=',', signed=True, unsigned=True):\n",
    "    out = dict()\n",
    "    for col in int_cols:\n",
    "        out[col] = downcast_int(file, col, delimiter=delimiter, signed=signed, unsigned=unsigned)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34857117-7869-4132-8ed6-b148c95a6e5f",
   "metadata": {},
   "source": [
    "Optimize types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9243db11-d621-4790-a22f-163763165d3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/instagram-dataset/instagram_profiles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     print(ds.types)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m---> 12\u001b[0m     ds\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     avg_mem_unoptimized \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ds\u001b[38;5;241m.\u001b[39mfile_name, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msid\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, nrows\u001b[38;5;241m=\u001b[39mSAMPLE_SIZE)\u001b[38;5;241m.\u001b[39mmemory_usage(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mSAMPLE_SIZE\n\u001b[1;32m     14\u001b[0m     avg_mem_optimized \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mmemory_usage(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mSAMPLE_SIZE\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/instagram-dataset/instagram_profiles.csv'"
     ]
    }
   ],
   "source": [
    "for ds in datasets:\n",
    "    if not ds.load_types():\n",
    "        int_cols = [k for k,v in ds.types.items() if v == 'Int64']\n",
    "        print(int_cols)\n",
    "        ds.types.update(optimize_cols(ds.file_name, int_cols, delimiter='\\t'))\n",
    "        print(f'Optimized {len(int_cols)} types for {ds.name()}')\n",
    "    ds.save_types()\n",
    "\n",
    "for ds in datasets:\n",
    "    ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'], nrows=SAMPLE_SIZE)\n",
    "    avg_mem_unoptimized = pd.read_csv(ds.file_name, index_col='sid', delimiter='\\t', nrows=SAMPLE_SIZE).memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    avg_mem_optimized = ds.df.memory_usage(deep=True).sum()/SAMPLE_SIZE\n",
    "    print(f'{ds.name().ljust(19)} mean optimized memory usage per entry:  {round(avg_mem_optimized):3} B vs {round(avg_mem_unoptimized):4} B  : {round(avg_mem_optimized/avg_mem_unoptimized*100,2):5}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17f2b6-63f3-45f8-9434-6e45b4af5ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815e13f5-237e-4a6b-89a2-923dd1b41b3f",
   "metadata": {},
   "source": [
    "## RQ1 - EDA\n",
    "Andrea\n",
    "\n",
    "#### Profiles \n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| profile_id | Instagrams ID |\n",
    "| profile_name | profile name |\n",
    "| firstname_lastname | firstname lastname |\n",
    "| description | May contain '\\n' |\n",
    "| following | Number of following profile at the moment it was visited |\n",
    "| followers | Number of followers at the moment it was visited |\n",
    "| n_posts | Number of posts at the moment it was visited |\n",
    "| url | Url in profile description |\n",
    "| cts | Timestamp when the profile was visited |\n",
    "| is_business_account | Boolean flag if that profile was makred by the owner as business account |\n",
    "\n",
    "#### Locations\n",
    "\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| ID | Instagrams ID |\n",
    "| Name | Locations Name |\n",
    "| Street | Street Address, may contain '\\n' |\n",
    "| ZIP | Zip code |\n",
    "| City | City Name |\n",
    "| Region | Region |\n",
    "| CD | Country Code |\n",
    "| Phone | The phone in format as on the Instragram |\n",
    "| aj_exact_city_match | The Instagrams Internal key |\n",
    "| aj_exact_country_match | The Instagrams Internal key |\n",
    "| blurb | Description of the place, may contain '\\n' |\n",
    "| dir_city_id | The Instagrams internal City ID |\n",
    "| dir_city_name | city Name |\n",
    "| dir_city_slug | City tag (sortof) |\n",
    "| dir_country_id | Country ID |\n",
    "| dir_country_name | country |\n",
    "| lat | Latitude |\n",
    "| lng | Longtitude |\n",
    "| primary_alias_on_fb | Bool Flag |\n",
    "| slug | ??? |\n",
    "| website | The URL to web site, may contain more then 1 URL, may contain '\\n' |\n",
    "| cts | Timestamp when the location was visited |\n",
    "\n",
    "#### Posts\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| SID | Sequence ID |\n",
    "| sid_profile | Sequence ID of the profile from *Profiles* table |\n",
    "| post_id | Instagrams ID |\n",
    "| profile_id | Instagrams ID may be null |\n",
    "| location_id | Instagrams ID |\n",
    "| cts | Timestamp when the Post was created |\n",
    "| post_type | 1 - Photo, 2 - Video, 3 - multy |\n",
    "| description | May contain '\\n' |\n",
    "| number_likes | Number of Likes at the moment it was visited |\n",
    "| number_comments | Number of comments at the moment it was visited |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be3cdf-712c-41be-b8a2-bd3324a97d3e",
   "metadata": {},
   "source": [
    "## RQ2\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835228dd-db37-4a40-b200-6393143cc866",
   "metadata": {},
   "source": [
    "## RQ3\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f655c1e-46e4-4634-9654-59cc62df9949",
   "metadata": {},
   "source": [
    "## RQ4\n",
    "Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbbd88-6c95-4da3-a4f9-8d0394e61a82",
   "metadata": {},
   "source": [
    "## RQ5\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be90c63-7465-4d25-a14e-fc5c21837976",
   "metadata": {},
   "source": [
    "## RQ6\n",
    "Matteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba74355-9452-4263-bd24-3713fbfdcf4f",
   "metadata": {},
   "source": [
    "## RQ7\n",
    "Andrea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2612d-c19c-4a26-ad22-192568f7a542",
   "metadata": {},
   "source": [
    "## RQ8\n",
    "Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4915e-cd96-4953-924c-5635c16c5483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
