{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport random\nimport re\nimport os\nimport timeit\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-19T13:34:53.219477Z","iopub.execute_input":"2022-10-19T13:34:53.219982Z","iopub.status.idle":"2022-10-19T13:34:54.837999Z","shell.execute_reply.started":"2022-10-19T13:34:53.219863Z","shell.execute_reply":"2022-10-19T13:34:54.836149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From specifications and descriptions of the dataset we can infer the proper `dtype` for most of the columns:\n- numerical : `int`,`float`\n- text : `str`\n- A low/finite number of values : `categorical`,`boolean`","metadata":{}},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, file:str):\n        self.file_name : str = file\n        self.types : dict = self.load_types()\n        self.df : pd.DataFrame = None\n        \n    def name(self):\n        return re.search(r'\\/([\\w\\d]*)\\.csv',self.file_name).group(1)\n    \n    def types_file(self):\n        return '/kaggle/working/'+ self.name() +'.npy'\n        \n    def save_types(self):\n        np.save(self.types_file(), self.types)\n        \n    def load_types(self):\n        if os.path.isfile(self.types_file()):\n            self.types = np.load(self.types_file(),allow_pickle='TRUE').item()\n            return self.types\n        return None\n    \n    def __getitem__(self,item):\n        return self.df[item]\n\n\ndatasets = [\n    Dataset(file='../input/instagram-dataset/instagram_profiles.csv'), \n    Dataset(file='../input/instagram-dataset/instagram_locations.csv'), \n    Dataset(file='../input/instagram-dataset/instagram_posts.csv')\n]\nprofiles, locations, posts = datasets\n\nprofiles.types = {\n#     'sid' : int,\n    'profile_id' : int,\n    'profile_name' : pd.StringDtype(storage='pyarrow'),\n    'firstname_lastname' : pd.StringDtype(storage='pyarrow'),\n    'description' : pd.StringDtype(storage='pyarrow'),\n    'following' : int,\n    'followers' : int,\n    'n_posts' : int,\n    'url' : pd.StringDtype(storage='pyarrow'),\n#     'cts' : pd.DatetimeTZDtype(tz='UTC'), #obtained through parse_dates=['cts']\n    'is_business_account' : pd.BooleanDtype()\n}\nposts.types = {\n#     'sid' : int, # gives an error, maybe because it's the index?\n    'sid_profile' : int,\n    'post_id' : pd.StringDtype(storage='pyarrow'),\n    'profile_id' : int,\n    'location_id' : int,\n    'description' : pd.StringDtype(storage='pyarrow'),\n    'post_type' : pd.CategoricalDtype(categories=[1,2,3]),\n    'numbr_likes' : int,\n    'number_comments' : int\n}\nlocations.types = {\n#     'sid' : int, # gives an error, maybe because it's the index?\n    'id' : int,\n    'name' : pd.StringDtype(storage='pyarrow'),\n    'street' : pd.StringDtype(storage='pyarrow'),\n    'zip' : pd.StringDtype(storage='pyarrow'),\n    'city' : pd.StringDtype(storage='pyarrow'),\n    'region' : pd.StringDtype(storage='pyarrow'),\n    'cd' : pd.CategoricalDtype(),\n    'phone' : pd.StringDtype(storage='pyarrow'),\n    'aj_exact_city_match' : pd.BooleanDtype(),\n    'aj_exact_country_match' : pd.BooleanDtype(),\n    'blurb' : pd.StringDtype(storage='pyarrow'),\n    'dir_city_id' : pd.StringDtype(storage='pyarrow'),\n    'dir_city_name' : pd.StringDtype(storage='pyarrow'),\n    'dir_city_slug' : pd.StringDtype(storage='pyarrow'),\n    'dir_country_id' : pd.CategoricalDtype(),\n    'dir_country_name' : pd.CategoricalDtype(),\n    'lat' : pd.Float32Dtype(),\n    'lng' : pd.Float32Dtype(),\n    'primary_alias_on_fb' : pd.StringDtype(storage='pyarrow'),\n    'slug' : pd.StringDtype(storage='pyarrow'),\n    'website' : pd.StringDtype(storage='pyarrow'),\n}","metadata":{"execution":{"iopub.status.busy":"2022-10-19T11:01:19.112277Z","iopub.execute_input":"2022-10-19T11:01:19.112703Z","iopub.status.idle":"2022-10-19T11:01:19.132644Z","shell.execute_reply.started":"2022-10-19T11:01:19.112667Z","shell.execute_reply":"2022-10-19T11:01:19.131367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_types(signed=True, unsigned=True, custom=[]):\n    '''Returns a pandas dataframe containing the boundaries of each integer dtype'''\n    # based on https://stackoverflow.com/a/57894540/9419492\n    pd_types = custom\n    if signed:\n        pd_types += [pd.Int8Dtype() ,pd.Int16Dtype() ,pd.Int32Dtype(), pd.Int64Dtype()]\n    if unsigned:\n        pd_types += [pd.UInt8Dtype() ,pd.UInt16Dtype(), pd.UInt32Dtype(), pd.UInt64Dtype()]\n    type_df = pd.DataFrame(data=pd_types, columns=['pd_type'])\n    type_df['np_type'] = type_df['pd_type'].apply(lambda t: t.numpy_dtype)\n    type_df['min_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).min)\n    type_df['max_value'] = type_df['np_type'].apply(lambda row: np.iinfo(row).max)\n    type_df['allow_negatives'] = type_df['min_value'] < 0\n    type_df['size'] = type_df['np_type'].apply(lambda row: row.itemsize)\n    type_df.sort_values(by=['size', 'allow_negatives'], inplace=True)\n    return type_df.reset_index(drop=True)\n    \nget_types()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T11:01:19.522407Z","iopub.execute_input":"2022-10-19T11:01:19.522853Z","iopub.status.idle":"2022-10-19T11:01:19.551365Z","shell.execute_reply.started":"2022-10-19T11:01:19.522814Z","shell.execute_reply":"2022-10-19T11:01:19.550518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downcast_int(file_path, column:str, chunksize=10000, delimiter=',', signed=True, unsigned=True):\n    '''Assigns the smallest possible dtype to an integer column of a csv'''\n    types = get_types(signed, unsigned)\n    negatives = False\n    for chunk in pd.read_csv(file_path, usecols=[column],delimiter=delimiter,skiprows=lambda x:x%100==0,chunksize=chunksize):\n        M = chunk[column].max()\n        m = chunk[column].min()\n        if not signed and not negatives and m < 0 :\n            types = types[types['allow_negatives']] # removes unsigned rows\n            negatives = True\n        if m < types['min_value'].iloc[0]:\n            types = types[types['min_value'] < m]\n        if M > types['max_value'].iloc[0]:\n            types = types[types['max_value'] > M]\n        if len(types) == 1:\n            print('early stop')\n            break\n    return types['pd_type'].iloc[0]\n\ndef optimize_cols(file, int_cols, delimiter=',', signed=True, unsigned=True):\n    out = dict()\n    for col in int_cols:\n        out[col] = downcast_int(file, col, delimiter=delimiter, signed=signed, unsigned=unsigned)\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-10-19T11:02:06.192444Z","iopub.execute_input":"2022-10-19T11:02:06.193210Z","iopub.status.idle":"2022-10-19T11:02:06.204350Z","shell.execute_reply.started":"2022-10-19T11:02:06.193155Z","shell.execute_reply":"2022-10-19T11:02:06.203163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ds in datasets:\n    if not ds.load_types():\n        int_cols = [k for k,v in ds.types.items() if v is int]\n        print(int_cols)\n        ds.types.update(optimize_cols(ds.file_name, int_cols, delimiter='\\t'))\n        print(f'Optimized {len(int_cols)} types for {ds.name()}')\n#     ds.types.update({k:pd.StringDtype(storage='pyarrow') for k,v in ds.types.items() if v==pd.StringDtype(storage='pyarrow')})\n    ds.save_types()\n#     print(ds.types)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T11:02:06.681181Z","iopub.execute_input":"2022-10-19T11:02:06.682115Z","iopub.status.idle":"2022-10-19T11:02:06.691149Z","shell.execute_reply.started":"2022-10-19T11:02:06.682068Z","shell.execute_reply":"2022-10-19T11:02:06.690011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAMPLE_SIZE = 10000\nfor ds in datasets:\n    ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'], nrows=SAMPLE_SIZE)\n    avg_mem_unoptimized = pd.read_csv(ds.file_name, index_col='sid', delimiter='\\t', nrows=SAMPLE_SIZE).memory_usage(deep=True).sum()/SAMPLE_SIZE\n    avg_mem_optimized = ds.df.memory_usage(deep=True).sum()/SAMPLE_SIZE\n    print(f'{ds.name().ljust(19)} mean optimized memory usage per entry:  {round(avg_mem_optimized):3} B vs {round(avg_mem_unoptimized):4} B  : {round(avg_mem_optimized/avg_mem_unoptimized*100,2):5}%') ","metadata":{"execution":{"iopub.status.busy":"2022-10-19T11:01:21.906043Z","iopub.execute_input":"2022-10-19T11:01:21.906682Z","iopub.status.idle":"2022-10-19T11:01:21.944710Z","shell.execute_reply.started":"2022-10-19T11:01:21.906647Z","shell.execute_reply":"2022-10-19T11:01:21.943086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test:  fails even with optimizing can't load everything in 16GB\n# for ds in datasets:\n#     ds.df = pd.read_csv(ds.file_name, dtype=ds.types, index_col='sid', delimiter='\\t', parse_dates=['cts'])\n#     print(f'Loaded {ds.name().ljust(19)}, size = {round(ds.df.memory_usage(deep=True).sum()/ 1024**3,2)}GB')\n#     del ds.df","metadata":{"execution":{"iopub.status.busy":"2022-10-19T10:16:22.492166Z","iopub.execute_input":"2022-10-19T10:16:22.492567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis [RQ1]","metadata":{}},{"cell_type":"markdown","source":"### Profiles \n| Field | Description |\n|---|---|\n| SID | Sequence ID |\n| profile_id | Instagrams ID |\n| profile_name | profile name |\n| firstname_lastname | firstname lastname |\n| description | May contain '\\n' |\n| following | Number of following profile at the moment it was visited |\n| followers | Number of followers at the moment it was visited |\n| n_posts | Number of posts at the moment it was visited |\n| url | Url in profile description |\n| cts | Timestamp when the profile was visited |\n| is_business_account | Boolean flag if that profile was makred by the owner as business account |","metadata":{}},{"cell_type":"code","source":"profiles.df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:25:41.527090Z","iopub.execute_input":"2022-10-18T13:25:41.528407Z","iopub.status.idle":"2022-10-18T13:25:41.550518Z","shell.execute_reply.started":"2022-10-18T13:25:41.528348Z","shell.execute_reply":"2022-10-18T13:25:41.549172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profiles.df[['following', 'followers', 'n_posts']].describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:55:12.511463Z","iopub.execute_input":"2022-10-18T13:55:12.511925Z","iopub.status.idle":"2022-10-18T13:55:12.553655Z","shell.execute_reply.started":"2022-10-18T13:55:12.511888Z","shell.execute_reply":"2022-10-18T13:55:12.552288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profiles.df.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:55:13.557683Z","iopub.execute_input":"2022-10-18T13:55:13.558110Z","iopub.status.idle":"2022-10-18T13:55:13.576884Z","shell.execute_reply.started":"2022-10-18T13:55:13.558076Z","shell.execute_reply":"2022-10-18T13:55:13.575433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locations\n\n| Field | Description |\n|---|---|\n| SID | Sequence ID |\n| ID | Instagrams ID |\n| Name | Locations Name |\n| Street | Street Address, may contain '\\n' |\n| ZIP | Zip code |\n| City | City Name |\n| Region | Region |\n| CD | Country Code |\n| Phone | The phone in format as on the Instragram |\n| aj_exact_city_match | The Instagrams Internal key |\n| aj_exact_country_match | The Instagrams Internal key |\n| blurb | Description of the place, may contain '\\n' |\n| dir_city_id | The Instagrams internal City ID |\n| dir_city_name | city Name |\n| dir_city_slug | City tag (sortof) |\n| dir_country_id | Country ID |\n| dir_country_name | country |\n| lat | Latitude |\n| lng | Longtitude |\n| primary_alias_on_fb | Bool Flag |\n| slug | ??? |\n| website | The URL to web site, may contain more then 1 URL, may contain '\\n' |\n| cts | Timestamp when the location was visited |","metadata":{}},{"cell_type":"code","source":"locations.df.iloc[:,:10].head()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T14:09:38.839954Z","iopub.execute_input":"2022-10-18T14:09:38.841059Z","iopub.status.idle":"2022-10-18T14:09:38.860880Z","shell.execute_reply.started":"2022-10-18T14:09:38.841016Z","shell.execute_reply":"2022-10-18T14:09:38.859593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations.df.iloc[:,10:].head()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T14:14:22.867673Z","iopub.execute_input":"2022-10-18T14:14:22.868107Z","iopub.status.idle":"2022-10-18T14:14:22.893393Z","shell.execute_reply.started":"2022-10-18T14:14:22.868074Z","shell.execute_reply":"2022-10-18T14:14:22.891371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations.df.describe()\n# it's useless","metadata":{"execution":{"iopub.status.busy":"2022-10-18T14:12:45.767986Z","iopub.execute_input":"2022-10-18T14:12:45.768439Z","iopub.status.idle":"2022-10-18T14:12:45.824304Z","shell.execute_reply.started":"2022-10-18T14:12:45.768403Z","shell.execute_reply":"2022-10-18T14:12:45.822869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations.df.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T14:12:49.598949Z","iopub.execute_input":"2022-10-18T14:12:49.599449Z","iopub.status.idle":"2022-10-18T14:12:49.629740Z","shell.execute_reply.started":"2022-10-18T14:12:49.599407Z","shell.execute_reply":"2022-10-18T14:12:49.628355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Posts\n| Field | Description |\n|---|---|\n| SID | Sequence ID |\n| sid_profile | Sequence ID of the profile from *Profiles* table |\n| post_id | Instagrams ID |\n| profile_id | Instagrams ID may be null |\n| location_id | Instagrams ID |\n| cts | Timestamp when the Post was created |\n| post_type | 1 - Photo, 2 - Video, 3 - multy |\n| description | May contain '\\n' |\n| number_likes | Number of Likes at the moment it was visited |\n| number_comments | Number of comments at the moment it was visited |","metadata":{}},{"cell_type":"code","source":"# posts.columns = posts.columns.str.replace('numbr', 'number')\nposts.df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:52:00.007853Z","iopub.execute_input":"2022-10-18T13:52:00.008291Z","iopub.status.idle":"2022-10-18T13:52:00.028460Z","shell.execute_reply.started":"2022-10-18T13:52:00.008257Z","shell.execute_reply":"2022-10-18T13:52:00.027236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"posts.df[['number_likes','number_comments']].describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:18:36.558117Z","iopub.status.idle":"2022-10-18T13:18:36.558491Z","shell.execute_reply.started":"2022-10-18T13:18:36.558316Z","shell.execute_reply":"2022-10-18T13:18:36.558332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"posts.df.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:51:53.006146Z","iopub.execute_input":"2022-10-18T13:51:53.006694Z","iopub.status.idle":"2022-10-18T13:51:53.028788Z","shell.execute_reply.started":"2022-10-18T13:51:53.006639Z","shell.execute_reply":"2022-10-18T13:51:53.027452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Chunking \n# for chunk in pandas.read_csv(\"FILE.csv\", chunksize=1000):\n#     pass","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:18:36.560722Z","iopub.status.idle":"2022-10-18T13:18:36.561081Z","shell.execute_reply.started":"2022-10-18T13:18:36.560896Z","shell.execute_reply":"2022-10-18T13:18:36.560912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"categorical## Before Starting\nWe note that this dataset has many odd values, with many columns having missing values that we'll have to deal somehow\n\nFurthermore we need to adjust all those columns having datetime objects not actually being represented as objects","metadata":{}},{"cell_type":"code","source":"# done above","metadata":{"execution":{"iopub.status.busy":"2022-10-18T13:18:36.562120Z","iopub.status.idle":"2022-10-18T13:18:36.562491Z","shell.execute_reply.started":"2022-10-18T13:18:36.562313Z","shell.execute_reply":"2022-10-18T13:18:36.562330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_problematic(df):\n    at_least_one_null = len(df[pd.isnull(df).any(axis=1)])\n    return at_least_one_null, len(df) - at_least_one_null\n\nfor i, df in enumerate([posts, locations, profiles]):\n    plt.subplot(1,3,i+1)\n#     plt.title(name)\n    plt.pie(count_problematic(df), labels=['missing values', ''])","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:11:03.690203Z","iopub.execute_input":"2022-10-18T15:11:03.690601Z","iopub.status.idle":"2022-10-18T15:11:03.946514Z","shell.execute_reply.started":"2022-10-18T15:11:03.690569Z","shell.execute_reply":"2022-10-18T15:11:03.944946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [RQ2] ","metadata":{}},{"cell_type":"markdown","source":"#### Plot the number of posts for each profile in descending order.","metadata":{}},{"cell_type":"code","source":"profiles.df.sort_values(by='n_posts', ascending=False)[['profile_name', 'n_posts']]","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:11:37.271619Z","iopub.execute_input":"2022-10-18T15:11:37.272450Z","iopub.status.idle":"2022-10-18T15:11:37.301748Z","shell.execute_reply.started":"2022-10-18T15:11:37.272407Z","shell.execute_reply":"2022-10-18T15:11:37.300567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### What posts have the most number of likes?","metadata":{}},{"cell_type":"code","source":"posts.df.sort_values(by='numbr_likes', ascending=False).head(10)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:11:56.329250Z","iopub.execute_input":"2022-10-18T15:11:56.329718Z","iopub.status.idle":"2022-10-18T15:11:56.364207Z","shell.execute_reply.started":"2022-10-18T15:11:56.329679Z","shell.execute_reply":"2022-10-18T15:11:56.362729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### What posts have the most and the least number of comments?","metadata":{}},{"cell_type":"code","source":"posts.df.sort_values(by='number_comments', ascending=False).head(10)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:12:22.316515Z","iopub.execute_input":"2022-10-18T15:12:22.316995Z","iopub.status.idle":"2022-10-18T15:12:22.351419Z","shell.execute_reply.started":"2022-10-18T15:12:22.316957Z","shell.execute_reply":"2022-10-18T15:12:22.349133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"posts.df.sort_values(by='number_comments', ascending=True).head(10)","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:12:23.603282Z","iopub.execute_input":"2022-10-18T15:12:23.603783Z","iopub.status.idle":"2022-10-18T15:12:23.631044Z","shell.execute_reply.started":"2022-10-18T15:12:23.603741Z","shell.execute_reply":"2022-10-18T15:12:23.629328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### How many posts include tagged locations, and how many do not? Show it using an appropriate chart and comment your results.","metadata":{}},{"cell_type":"code","source":"null_locations = sum(posts['location_id'].isna())\nplt.pie([null_locations, len(posts.df)-null_locations], labels=['null', 'tagged'])","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:12:42.844049Z","iopub.execute_input":"2022-10-18T15:12:42.844518Z","iopub.status.idle":"2022-10-18T15:12:42.978465Z","shell.execute_reply.started":"2022-10-18T15:12:42.844482Z","shell.execute_reply":"2022-10-18T15:12:42.974939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### How many posts include only photos? How many also have videos?","metadata":{}},{"cell_type":"code","source":"def categorize(mapping, values):\n    res = pd.DataFrame.from_dict(mapping, orient='index', columns=['count'])\n    for k,v in mapping.items():\n        res.loc[k] = sum(values == v)\n    res.loc['NA'] = sum(values.isna())\n    if res.loc['NA'].sum() == 0:\n        return res.loc[mapping.keys()]\n    else:\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:12:54.868618Z","iopub.execute_input":"2022-10-18T15:12:54.869066Z","iopub.status.idle":"2022-10-18T15:12:54.878631Z","shell.execute_reply.started":"2022-10-18T15:12:54.869034Z","shell.execute_reply":"2022-10-18T15:12:54.876932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"post_types = posts['post_type'].value_counts(dropna=False)\nsns.barplot(y=post_types, x=post_types.index).set(title='Post types')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:12:57.333212Z","iopub.execute_input":"2022-10-18T15:12:57.333664Z","iopub.status.idle":"2022-10-18T15:12:57.554271Z","shell.execute_reply.started":"2022-10-18T15:12:57.333627Z","shell.execute_reply":"2022-10-18T15:12:57.553022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### What's the percentage of business accounts vs non-business? What can you interpret regarding that percentage?","metadata":{}},{"cell_type":"code","source":"business_accounts = profiles.df['is_business_account'].value_counts(dropna=False)\nsns.barplot(x=[True, False, '<NA>'], y=business_accounts).set(title='Business Accounts')","metadata":{"execution":{"iopub.status.busy":"2022-10-18T15:14:59.450535Z","iopub.execute_input":"2022-10-18T15:14:59.451218Z","iopub.status.idle":"2022-10-18T15:14:59.682633Z","shell.execute_reply.started":"2022-10-18T15:14:59.451167Z","shell.execute_reply":"2022-10-18T15:14:59.681245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}